[2016-07-21 22:26:01,638][INFO ][node                     ] [Namorita] version[2.3.4], pid[10025], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-21 22:26:01,638][INFO ][node                     ] [Namorita] initializing ...
[2016-07-21 22:26:02,531][INFO ][plugins                  ] [Namorita] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-21 22:26:02,567][INFO ][env                      ] [Namorita] using [1] data paths, mounts [[/ (/dev/sda2)]], net usable_space [36.4gb], net total_space [131.3gb], spins? [no], types [ext4]
[2016-07-21 22:26:02,567][INFO ][env                      ] [Namorita] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-21 22:26:05,813][INFO ][node                     ] [Namorita] initialized
[2016-07-21 22:26:05,814][INFO ][node                     ] [Namorita] starting ...
[2016-07-21 22:26:06,031][INFO ][transport                ] [Namorita] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}
[2016-07-21 22:26:06,040][INFO ][discovery                ] [Namorita] elasticsearch/FxyPLkPNRtS-CTtL-FgFnA
[2016-07-21 22:26:09,121][INFO ][cluster.service          ] [Namorita] new_master {Namorita}{FxyPLkPNRtS-CTtL-FgFnA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-21 22:26:09,160][INFO ][http                     ] [Namorita] publish_address {127.0.0.1:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}
[2016-07-21 22:26:09,161][INFO ][node                     ] [Namorita] started
[2016-07-21 22:26:09,195][INFO ][gateway                  ] [Namorita] recovered [0] indices into cluster_state
[2016-07-21 22:26:20,035][INFO ][node                     ] [Namorita] stopping ...
[2016-07-21 22:26:20,063][INFO ][node                     ] [Namorita] stopped
[2016-07-21 22:26:20,064][INFO ][node                     ] [Namorita] closing ...
[2016-07-21 22:26:20,075][INFO ][node                     ] [Namorita] closed
[2016-07-21 22:46:47,815][INFO ][node                     ] [Wicked] version[2.3.4], pid[11901], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-21 22:46:47,816][INFO ][node                     ] [Wicked] initializing ...
[2016-07-21 22:46:48,916][INFO ][plugins                  ] [Wicked] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-21 22:46:48,957][INFO ][env                      ] [Wicked] using [1] data paths, mounts [[/ (/dev/sda2)]], net usable_space [41.9gb], net total_space [131.3gb], spins? [no], types [ext4]
[2016-07-21 22:46:48,958][INFO ][env                      ] [Wicked] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-21 22:46:52,843][INFO ][node                     ] [Wicked] initialized
[2016-07-21 22:46:52,843][INFO ][node                     ] [Wicked] starting ...
[2016-07-21 22:46:53,202][INFO ][transport                ] [Wicked] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}
[2016-07-21 22:46:53,218][INFO ][discovery                ] [Wicked] elasticsearch/NDpYBOVFQDaYnfV5Wf8myA
[2016-07-21 22:46:56,368][INFO ][cluster.service          ] [Wicked] new_master {Wicked}{NDpYBOVFQDaYnfV5Wf8myA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-21 22:46:56,418][INFO ][http                     ] [Wicked] publish_address {127.0.0.1:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}
[2016-07-21 22:46:56,419][INFO ][node                     ] [Wicked] started
[2016-07-21 22:46:56,462][INFO ][gateway                  ] [Wicked] recovered [0] indices into cluster_state
[2016-07-21 22:59:19,890][INFO ][node                     ] [Wicked] stopping ...
[2016-07-21 22:59:19,913][INFO ][node                     ] [Wicked] stopped
[2016-07-21 22:59:19,914][INFO ][node                     ] [Wicked] closing ...
[2016-07-21 22:59:19,928][INFO ][node                     ] [Wicked] closed
[2016-07-21 23:00:18,086][INFO ][node                     ] [Eon] version[2.3.4], pid[13022], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-21 23:00:18,087][INFO ][node                     ] [Eon] initializing ...
[2016-07-21 23:00:18,891][INFO ][plugins                  ] [Eon] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-21 23:00:18,922][INFO ][env                      ] [Eon] using [1] data paths, mounts [[/ (/dev/sda2)]], net usable_space [41.6gb], net total_space [131.3gb], spins? [no], types [ext4]
[2016-07-21 23:00:18,922][INFO ][env                      ] [Eon] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-21 23:00:22,538][INFO ][node                     ] [Eon] initialized
[2016-07-21 23:00:22,538][INFO ][node                     ] [Eon] starting ...
[2016-07-21 23:00:22,664][INFO ][transport                ] [Eon] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}
[2016-07-21 23:00:22,673][INFO ][discovery                ] [Eon] elasticsearch/WZW1raB1TXKAbCNTZS1RBw
[2016-07-21 23:00:25,764][INFO ][cluster.service          ] [Eon] new_master {Eon}{WZW1raB1TXKAbCNTZS1RBw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-21 23:00:25,804][INFO ][http                     ] [Eon] publish_address {127.0.0.1:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}
[2016-07-21 23:00:25,805][INFO ][node                     ] [Eon] started
[2016-07-21 23:00:25,826][INFO ][gateway                  ] [Eon] recovered [0] indices into cluster_state
[2016-07-21 23:00:33,491][INFO ][cluster.metadata         ] [Eon] [.kibana] creating index, cause [api], templates [], shards [1]/[1], mappings [config]
[2016-07-21 23:00:33,890][INFO ][cluster.routing.allocation] [Eon] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[.kibana][0]] ...]).
[2016-07-21 23:06:13,018][INFO ][cluster.metadata         ] [Eon] [.kibana] create_mapping [index-pattern]
[2016-07-21 23:29:51,822][INFO ][node                     ] [Eon] stopping ...
[2016-07-21 23:29:51,875][INFO ][node                     ] [Eon] stopped
[2016-07-21 23:29:51,876][INFO ][node                     ] [Eon] closing ...
[2016-07-21 23:29:51,888][INFO ][node                     ] [Eon] closed
[2016-07-22 09:15:01,116][INFO ][node                     ] [Siege] version[2.3.4], pid[821], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:15:01,116][INFO ][node                     ] [Siege] initializing ...
[2016-07-22 09:15:01,929][INFO ][plugins                  ] [Siege] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:15:01,986][INFO ][env                      ] [Siege] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [256gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:15:01,986][INFO ][env                      ] [Siege] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:15:01,987][WARN ][env                      ] [Siege] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:15:04,452][INFO ][node                     ] [Siege] initialized
[2016-07-22 09:15:04,452][INFO ][node                     ] [Siege] starting ...
[2016-07-22 09:15:04,647][INFO ][transport                ] [Siege] publish_address {127.0.0.1:9300}, bound_addresses {[fe80::1]:9300}, {[::1]:9300}, {127.0.0.1:9300}
[2016-07-22 09:15:04,671][INFO ][discovery                ] [Siege] elasticsearch/OrsWhLlQS0CuQTIKBNrKJA
[2016-07-22 09:15:07,721][INFO ][cluster.service          ] [Siege] new_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-22 09:15:07,735][INFO ][http                     ] [Siege] publish_address {127.0.0.1:9200}, bound_addresses {[fe80::1]:9200}, {[::1]:9200}, {127.0.0.1:9200}
[2016-07-22 09:15:07,735][INFO ][node                     ] [Siege] started
[2016-07-22 09:15:07,780][INFO ][gateway                  ] [Siege] recovered [1] indices into cluster_state
[2016-07-22 09:15:08,202][INFO ][cluster.routing.allocation] [Siege] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[.kibana][0]] ...]).
[2016-07-22 09:30:03,127][INFO ][node                     ] [Aminedi] version[2.3.4], pid[947], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:30:03,136][INFO ][node                     ] [Aminedi] initializing ...
[2016-07-22 09:30:03,912][INFO ][plugins                  ] [Aminedi] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:30:03,942][INFO ][env                      ] [Aminedi] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:30:03,942][INFO ][env                      ] [Aminedi] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:30:03,943][WARN ][env                      ] [Aminedi] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:30:07,050][INFO ][node                     ] [Aminedi] initialized
[2016-07-22 09:30:07,051][INFO ][node                     ] [Aminedi] starting ...
[2016-07-22 09:30:07,170][INFO ][transport                ] [Aminedi] publish_address {127.0.0.1:9301}, bound_addresses {[fe80::1]:9301}, {[::1]:9301}, {127.0.0.1:9301}
[2016-07-22 09:30:07,174][INFO ][discovery                ] [Aminedi] elasticsearch/SSnVPscAQoCov44svGwSyQ
[2016-07-22 09:30:10,262][INFO ][cluster.service          ] [Siege] added {{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-join(join from node[{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301}])
[2016-07-22 09:30:10,270][INFO ][cluster.service          ] [Aminedi] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:30:10,336][INFO ][http                     ] [Aminedi] publish_address {127.0.0.1:9201}, bound_addresses {[fe80::1]:9201}, {[::1]:9201}, {127.0.0.1:9201}
[2016-07-22 09:30:10,336][INFO ][node                     ] [Aminedi] started
[2016-07-22 09:30:10,808][INFO ][cluster.routing.allocation] [Siege] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.kibana][0]] ...]).
[2016-07-22 09:31:55,711][INFO ][node                     ] [Joshua Guthrie] version[2.3.4], pid[971], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:31:55,712][INFO ][node                     ] [Joshua Guthrie] initializing ...
[2016-07-22 09:31:56,464][INFO ][plugins                  ] [Joshua Guthrie] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:31:56,502][INFO ][env                      ] [Joshua Guthrie] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:31:56,502][INFO ][env                      ] [Joshua Guthrie] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:31:56,503][WARN ][env                      ] [Joshua Guthrie] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:31:59,019][INFO ][node                     ] [Joshua Guthrie] initialized
[2016-07-22 09:31:59,019][INFO ][node                     ] [Joshua Guthrie] starting ...
[2016-07-22 09:31:59,144][INFO ][transport                ] [Joshua Guthrie] publish_address {127.0.0.1:9302}, bound_addresses {[fe80::1]:9302}, {[::1]:9302}, {127.0.0.1:9302}
[2016-07-22 09:31:59,149][INFO ][discovery                ] [Joshua Guthrie] elasticsearch/8v_mme0bQSOuVjlGsMp_Cg
[2016-07-22 09:32:02,233][INFO ][cluster.service          ] [Siege] added {{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-join(join from node[{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302}])
[2016-07-22 09:32:02,236][INFO ][cluster.service          ] [Aminedi] added {{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:32:02,243][INFO ][cluster.service          ] [Joshua Guthrie] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:32:02,319][INFO ][http                     ] [Joshua Guthrie] publish_address {127.0.0.1:9202}, bound_addresses {[fe80::1]:9202}, {[::1]:9202}, {127.0.0.1:9202}
[2016-07-22 09:32:02,319][INFO ][node                     ] [Joshua Guthrie] started
[2016-07-22 09:32:28,665][INFO ][node                     ] [Jerry Jaxon] version[2.3.4], pid[997], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:32:28,666][INFO ][node                     ] [Jerry Jaxon] initializing ...
[2016-07-22 09:32:29,456][INFO ][plugins                  ] [Jerry Jaxon] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:32:29,505][INFO ][env                      ] [Jerry Jaxon] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:32:29,505][INFO ][env                      ] [Jerry Jaxon] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:32:29,506][WARN ][env                      ] [Jerry Jaxon] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:32:32,310][INFO ][node                     ] [Jerry Jaxon] initialized
[2016-07-22 09:32:32,310][INFO ][node                     ] [Jerry Jaxon] starting ...
[2016-07-22 09:32:32,445][INFO ][transport                ] [Jerry Jaxon] publish_address {127.0.0.1:9303}, bound_addresses {[fe80::1]:9303}, {[::1]:9303}, {127.0.0.1:9303}
[2016-07-22 09:32:32,449][INFO ][discovery                ] [Jerry Jaxon] elasticsearch/1W5bz2ywT3CetwfAdfjCZw
[2016-07-22 09:32:35,560][INFO ][cluster.service          ] [Siege] added {{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-join(join from node[{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303}])
[2016-07-22 09:32:35,563][INFO ][cluster.service          ] [Aminedi] added {{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:32:35,571][INFO ][cluster.service          ] [Jerry Jaxon] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:32:35,582][INFO ][cluster.service          ] [Joshua Guthrie] added {{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:32:35,683][INFO ][http                     ] [Jerry Jaxon] publish_address {127.0.0.1:9203}, bound_addresses {[fe80::1]:9203}, {[::1]:9203}, {127.0.0.1:9203}
[2016-07-22 09:32:35,684][INFO ][node                     ] [Jerry Jaxon] started
[2016-07-22 09:32:36,537][INFO ][node                     ] [Myron MacLain] version[2.3.4], pid[1018], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:32:36,538][INFO ][node                     ] [Myron MacLain] initializing ...
[2016-07-22 09:32:37,470][INFO ][plugins                  ] [Myron MacLain] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:32:37,521][INFO ][env                      ] [Myron MacLain] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:32:37,521][INFO ][env                      ] [Myron MacLain] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:32:37,523][WARN ][env                      ] [Myron MacLain] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:32:40,437][INFO ][node                     ] [Myron MacLain] initialized
[2016-07-22 09:32:40,437][INFO ][node                     ] [Myron MacLain] starting ...
[2016-07-22 09:32:40,577][INFO ][transport                ] [Myron MacLain] publish_address {127.0.0.1:9304}, bound_addresses {[fe80::1]:9304}, {[::1]:9304}, {127.0.0.1:9304}
[2016-07-22 09:32:40,589][INFO ][discovery                ] [Myron MacLain] elasticsearch/o5IOcsZaSpKa6-a_W_zgQQ
[2016-07-22 09:32:43,706][INFO ][cluster.service          ] [Siege] added {{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},}, reason: zen-disco-join(join from node[{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304}])
[2016-07-22 09:32:43,708][INFO ][cluster.service          ] [Aminedi] added {{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:32:43,711][INFO ][cluster.service          ] [Joshua Guthrie] added {{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:32:43,727][INFO ][cluster.service          ] [Jerry Jaxon] added {{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:32:43,742][INFO ][cluster.service          ] [Myron MacLain] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:32:43,830][INFO ][http                     ] [Myron MacLain] publish_address {127.0.0.1:9204}, bound_addresses {[fe80::1]:9204}, {[::1]:9204}, {127.0.0.1:9204}
[2016-07-22 09:32:43,830][INFO ][node                     ] [Myron MacLain] started
[2016-07-22 09:32:54,644][INFO ][node                     ] [Outrage] version[2.3.4], pid[1042], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:32:54,655][INFO ][node                     ] [Outrage] initializing ...
[2016-07-22 09:32:55,460][INFO ][plugins                  ] [Outrage] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:32:55,534][INFO ][env                      ] [Outrage] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:32:55,534][INFO ][env                      ] [Outrage] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:32:55,535][WARN ][env                      ] [Outrage] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:32:58,088][INFO ][node                     ] [Outrage] initialized
[2016-07-22 09:32:58,089][INFO ][node                     ] [Outrage] starting ...
[2016-07-22 09:32:58,281][INFO ][transport                ] [Outrage] publish_address {127.0.0.1:9305}, bound_addresses {[fe80::1]:9305}, {[::1]:9305}, {127.0.0.1:9305}
[2016-07-22 09:32:58,286][INFO ][discovery                ] [Outrage] elasticsearch/xbEPXtpzSoyBevWMLImNWA
[2016-07-22 09:33:01,426][INFO ][cluster.service          ] [Siege] added {{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},}, reason: zen-disco-join(join from node[{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305}])
[2016-07-22 09:33:01,429][INFO ][cluster.service          ] [Aminedi] added {{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:33:01,434][INFO ][cluster.service          ] [Jerry Jaxon] added {{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:33:01,435][INFO ][cluster.service          ] [Joshua Guthrie] added {{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:33:01,447][INFO ][cluster.service          ] [Myron MacLain] added {{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:33:01,459][INFO ][cluster.service          ] [Outrage] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:33:01,560][INFO ][http                     ] [Outrage] publish_address {127.0.0.1:9205}, bound_addresses {[fe80::1]:9205}, {[::1]:9205}, {127.0.0.1:9205}
[2016-07-22 09:33:01,561][INFO ][node                     ] [Outrage] started
[2016-07-22 09:33:53,599][INFO ][node                     ] [Red Ghost] version[2.3.4], pid[1080], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:33:53,613][INFO ][node                     ] [Red Ghost] initializing ...
[2016-07-22 09:33:54,331][INFO ][plugins                  ] [Red Ghost] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:33:54,366][INFO ][env                      ] [Red Ghost] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:33:54,366][INFO ][env                      ] [Red Ghost] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:33:54,367][WARN ][env                      ] [Red Ghost] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:33:56,860][INFO ][node                     ] [Red Ghost] initialized
[2016-07-22 09:33:56,861][INFO ][node                     ] [Red Ghost] starting ...
[2016-07-22 09:33:57,012][INFO ][transport                ] [Red Ghost] publish_address {127.0.0.1:9306}, bound_addresses {[fe80::1]:9306}, {[::1]:9306}, {127.0.0.1:9306}
[2016-07-22 09:33:57,021][INFO ][discovery                ] [Red Ghost] elasticsearch/ajK1yIvBS1GjMHXskFRa7g
[2016-07-22 09:34:00,168][INFO ][cluster.service          ] [Siege] added {{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},}, reason: zen-disco-join(join from node[{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306}])
[2016-07-22 09:34:00,194][INFO ][cluster.service          ] [Jerry Jaxon] added {{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:00,197][INFO ][cluster.service          ] [Myron MacLain] added {{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:00,199][INFO ][cluster.service          ] [Aminedi] added {{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:00,205][INFO ][cluster.service          ] [Joshua Guthrie] added {{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:00,208][INFO ][cluster.service          ] [Red Ghost] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:00,211][INFO ][cluster.service          ] [Outrage] added {{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:00,391][INFO ][http                     ] [Red Ghost] publish_address {127.0.0.1:9206}, bound_addresses {[fe80::1]:9206}, {[::1]:9206}, {127.0.0.1:9206}
[2016-07-22 09:34:00,391][INFO ][node                     ] [Red Ghost] started
[2016-07-22 09:34:14,633][INFO ][node                     ] [Siryn] version[2.3.4], pid[1105], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:34:14,634][INFO ][node                     ] [Siryn] initializing ...
[2016-07-22 09:34:15,383][INFO ][plugins                  ] [Siryn] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:34:15,425][INFO ][env                      ] [Siryn] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:34:15,425][INFO ][env                      ] [Siryn] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:34:15,426][WARN ][env                      ] [Siryn] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:34:17,652][INFO ][node                     ] [Siryn] initialized
[2016-07-22 09:34:17,652][INFO ][node                     ] [Siryn] starting ...
[2016-07-22 09:34:17,788][INFO ][transport                ] [Siryn] publish_address {127.0.0.1:9307}, bound_addresses {[fe80::1]:9307}, {[::1]:9307}, {127.0.0.1:9307}
[2016-07-22 09:34:17,797][INFO ][discovery                ] [Siryn] elasticsearch/nJhvAF8mQyaz1AJLR8L8FQ
[2016-07-22 09:34:20,915][INFO ][cluster.service          ] [Siege] added {{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},}, reason: zen-disco-join(join from node[{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307}])
[2016-07-22 09:34:20,922][INFO ][cluster.service          ] [Jerry Jaxon] added {{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:20,922][INFO ][cluster.service          ] [Joshua Guthrie] added {{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:20,923][INFO ][cluster.service          ] [Siryn] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:20,924][INFO ][cluster.service          ] [Myron MacLain] added {{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:20,930][INFO ][cluster.service          ] [Outrage] added {{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:20,933][INFO ][cluster.service          ] [Aminedi] added {{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:20,962][INFO ][cluster.service          ] [Red Ghost] added {{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:21,089][INFO ][http                     ] [Siryn] publish_address {127.0.0.1:9207}, bound_addresses {[fe80::1]:9207}, {[::1]:9207}, {127.0.0.1:9207}
[2016-07-22 09:34:21,089][INFO ][node                     ] [Siryn] started
[2016-07-22 09:34:50,303][INFO ][node                     ] [Cloud] version[2.3.4], pid[1127], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:34:50,316][INFO ][node                     ] [Cloud] initializing ...
[2016-07-22 09:34:51,127][INFO ][plugins                  ] [Cloud] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:34:51,160][INFO ][env                      ] [Cloud] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:34:51,160][INFO ][env                      ] [Cloud] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:34:51,161][WARN ][env                      ] [Cloud] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:34:53,537][INFO ][node                     ] [Cloud] initialized
[2016-07-22 09:34:53,537][INFO ][node                     ] [Cloud] starting ...
[2016-07-22 09:34:53,651][INFO ][transport                ] [Cloud] publish_address {127.0.0.1:9308}, bound_addresses {[fe80::1]:9308}, {[::1]:9308}, {127.0.0.1:9308}
[2016-07-22 09:34:53,656][INFO ][discovery                ] [Cloud] elasticsearch/jOV2nqHGTZCTsZaL05xnRA
[2016-07-22 09:34:56,789][INFO ][cluster.service          ] [Siege] added {{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},}, reason: zen-disco-join(join from node[{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308}])
[2016-07-22 09:34:56,820][INFO ][cluster.service          ] [Jerry Jaxon] added {{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:56,821][INFO ][cluster.service          ] [Red Ghost] added {{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:56,830][INFO ][cluster.service          ] [Joshua Guthrie] added {{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:56,831][INFO ][cluster.service          ] [Outrage] added {{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:56,828][INFO ][cluster.service          ] [Cloud] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:56,833][INFO ][cluster.service          ] [Myron MacLain] added {{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:56,843][INFO ][cluster.service          ] [Siryn] added {{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:56,834][INFO ][cluster.service          ] [Aminedi] added {{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:34:57,019][INFO ][http                     ] [Cloud] publish_address {127.0.0.1:9208}, bound_addresses {[fe80::1]:9208}, {[::1]:9208}, {127.0.0.1:9208}
[2016-07-22 09:34:57,019][INFO ][node                     ] [Cloud] started
[2016-07-22 09:35:03,156][INFO ][node                     ] [Eternal Brain] version[2.3.4], pid[1149], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:35:03,175][INFO ][node                     ] [Eternal Brain] initializing ...
[2016-07-22 09:35:03,947][INFO ][plugins                  ] [Eternal Brain] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:35:03,979][INFO ][env                      ] [Eternal Brain] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:35:03,979][INFO ][env                      ] [Eternal Brain] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:35:03,980][WARN ][env                      ] [Eternal Brain] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:35:06,355][INFO ][node                     ] [Eternal Brain] initialized
[2016-07-22 09:35:06,356][INFO ][node                     ] [Eternal Brain] starting ...
[2016-07-22 09:35:06,525][INFO ][transport                ] [Eternal Brain] publish_address {127.0.0.1:9309}, bound_addresses {[fe80::1]:9309}, {[::1]:9309}, {127.0.0.1:9309}
[2016-07-22 09:35:06,540][INFO ][discovery                ] [Eternal Brain] elasticsearch/Nn30dk_1TAetMMwupV72Hg
[2016-07-22 09:35:09,653][INFO ][cluster.service          ] [Siege] added {{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},}, reason: zen-disco-join(join from node[{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309}])
[2016-07-22 09:35:09,656][INFO ][cluster.service          ] [Jerry Jaxon] added {{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:09,657][INFO ][cluster.service          ] [Siryn] added {{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:09,662][INFO ][cluster.service          ] [Red Ghost] added {{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:09,665][INFO ][cluster.service          ] [Myron MacLain] added {{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:09,666][INFO ][cluster.service          ] [Aminedi] added {{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:09,673][INFO ][cluster.service          ] [Cloud] added {{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:09,667][INFO ][cluster.service          ] [Joshua Guthrie] added {{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:09,667][INFO ][cluster.service          ] [Outrage] added {{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:09,684][INFO ][cluster.service          ] [Eternal Brain] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:09,865][INFO ][http                     ] [Eternal Brain] publish_address {127.0.0.1:9209}, bound_addresses {[fe80::1]:9209}, {[::1]:9209}, {127.0.0.1:9209}
[2016-07-22 09:35:09,865][INFO ][node                     ] [Eternal Brain] started
[2016-07-22 09:35:25,835][INFO ][node                     ] [Eon] version[2.3.4], pid[1171], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:35:25,843][INFO ][node                     ] [Eon] initializing ...
[2016-07-22 09:35:26,481][INFO ][plugins                  ] [Eon] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:35:26,516][INFO ][env                      ] [Eon] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:35:26,517][INFO ][env                      ] [Eon] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:35:26,519][WARN ][env                      ] [Eon] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:35:28,764][INFO ][node                     ] [Eon] initialized
[2016-07-22 09:35:28,764][INFO ][node                     ] [Eon] starting ...
[2016-07-22 09:35:28,870][INFO ][transport                ] [Eon] publish_address {127.0.0.1:9310}, bound_addresses {[fe80::1]:9310}, {[::1]:9310}, {127.0.0.1:9310}
[2016-07-22 09:35:28,876][INFO ][discovery                ] [Eon] elasticsearch/DM2DlH7QT3CAtYcL5XoCgQ
[2016-07-22 09:35:31,984][INFO ][cluster.service          ] [Siege] added {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-join(join from node[{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310}])
[2016-07-22 09:35:31,987][INFO ][cluster.service          ] [Cloud] added {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:31,987][INFO ][cluster.service          ] [Siryn] added {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:31,991][INFO ][cluster.service          ] [Red Ghost] added {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:31,993][INFO ][cluster.service          ] [Myron MacLain] added {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:31,997][INFO ][cluster.service          ] [Jerry Jaxon] added {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:31,997][INFO ][cluster.service          ] [Joshua Guthrie] added {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:32,004][INFO ][cluster.service          ] [Outrage] added {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:32,009][INFO ][cluster.service          ] [Eon] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:32,000][INFO ][cluster.service          ] [Aminedi] added {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:32,063][INFO ][cluster.service          ] [Eternal Brain] added {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:32,042][WARN ][cluster.service          ] [Cloud] failed to connect to node [{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310}]
ConnectTransportException[[Eon][127.0.0.1:9310] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:35:32,248][INFO ][http                     ] [Eon] publish_address {127.0.0.1:9210}, bound_addresses {[fe80::1]:9210}, {[::1]:9210}, {127.0.0.1:9210}
[2016-07-22 09:35:32,256][INFO ][node                     ] [Eon] started
[2016-07-22 09:35:36,740][INFO ][node                     ] [Eon] stopping ...
[2016-07-22 09:35:36,747][INFO ][cluster.service          ] [Siege] removed {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-node_left({Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310})
[2016-07-22 09:35:36,753][INFO ][cluster.service          ] [Jerry Jaxon] removed {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:36,755][INFO ][cluster.service          ] [Siryn] removed {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:36,758][INFO ][cluster.service          ] [Joshua Guthrie] removed {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:36,759][INFO ][cluster.service          ] [Eternal Brain] removed {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:36,763][INFO ][cluster.service          ] [Cloud] removed {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:36,764][INFO ][cluster.service          ] [Outrage] removed {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:36,766][INFO ][cluster.service          ] [Red Ghost] removed {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:36,780][INFO ][cluster.service          ] [Aminedi] removed {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:36,795][INFO ][cluster.service          ] [Myron MacLain] removed {{Eon}{DM2DlH7QT3CAtYcL5XoCgQ}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:35:36,822][INFO ][node                     ] [Eon] stopped
[2016-07-22 09:35:36,822][INFO ][node                     ] [Eon] closing ...
[2016-07-22 09:35:36,829][INFO ][node                     ] [Eon] closed
[2016-07-22 09:36:01,507][INFO ][node                     ] [Space Turnip] version[2.3.4], pid[1195], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:36:01,507][INFO ][node                     ] [Space Turnip] initializing ...
[2016-07-22 09:36:02,197][INFO ][plugins                  ] [Space Turnip] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:36:02,235][INFO ][env                      ] [Space Turnip] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:36:02,235][INFO ][env                      ] [Space Turnip] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:36:02,236][WARN ][env                      ] [Space Turnip] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:36:04,986][INFO ][node                     ] [Space Turnip] initialized
[2016-07-22 09:36:05,001][INFO ][node                     ] [Space Turnip] starting ...
[2016-07-22 09:36:05,123][INFO ][transport                ] [Space Turnip] publish_address {127.0.0.1:9310}, bound_addresses {[fe80::1]:9310}, {[::1]:9310}, {127.0.0.1:9310}
[2016-07-22 09:36:05,128][INFO ][discovery                ] [Space Turnip] elasticsearch/8VZ66WpBQUadipGygkFTLw
[2016-07-22 09:36:08,203][INFO ][cluster.service          ] [Siege] added {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-join(join from node[{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310}])
[2016-07-22 09:36:08,206][INFO ][cluster.service          ] [Siryn] added {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:08,206][INFO ][cluster.service          ] [Cloud] added {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:08,208][INFO ][cluster.service          ] [Jerry Jaxon] added {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:08,210][INFO ][cluster.service          ] [Red Ghost] added {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:08,211][INFO ][cluster.service          ] [Myron MacLain] added {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:08,213][INFO ][cluster.service          ] [Joshua Guthrie] added {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:08,217][INFO ][cluster.service          ] [Eternal Brain] added {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:08,228][INFO ][cluster.service          ] [Space Turnip] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:08,221][INFO ][cluster.service          ] [Outrage] added {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:08,231][INFO ][cluster.service          ] [Aminedi] added {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:08,242][WARN ][cluster.service          ] [Eternal Brain] failed to connect to node [{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310}]
ConnectTransportException[[Space Turnip][127.0.0.1:9310] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:36:08,268][WARN ][cluster.service          ] [Myron MacLain] failed to connect to node [{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310}]
ConnectTransportException[[Space Turnip][127.0.0.1:9310] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:36:08,404][INFO ][http                     ] [Space Turnip] publish_address {127.0.0.1:9210}, bound_addresses {[fe80::1]:9210}, {[::1]:9210}, {127.0.0.1:9210}
[2016-07-22 09:36:08,404][INFO ][node                     ] [Space Turnip] started
[2016-07-22 09:36:09,274][WARN ][cluster.service          ] [Red Ghost] failed to connect to node [{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310}]
ConnectTransportException[[Space Turnip][127.0.0.1:9310] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:36:09,276][WARN ][cluster.service          ] [Joshua Guthrie] failed to connect to node [{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310}]
ConnectTransportException[[Space Turnip][127.0.0.1:9310] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:36:14,050][INFO ][node                     ] [Space Turnip] stopping ...
[2016-07-22 09:36:14,056][INFO ][cluster.service          ] [Siege] removed {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-node_left({Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310})
[2016-07-22 09:36:14,059][INFO ][cluster.service          ] [Siryn] removed {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:14,060][INFO ][cluster.service          ] [Jerry Jaxon] removed {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:14,062][INFO ][cluster.service          ] [Cloud] removed {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:14,072][INFO ][cluster.service          ] [Joshua Guthrie] removed {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:14,073][INFO ][cluster.service          ] [Eternal Brain] removed {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:14,073][INFO ][cluster.service          ] [Aminedi] removed {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:14,078][INFO ][cluster.service          ] [Outrage] removed {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:14,081][INFO ][cluster.service          ] [Red Ghost] removed {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:14,083][INFO ][cluster.service          ] [Myron MacLain] removed {{Space Turnip}{8VZ66WpBQUadipGygkFTLw}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:14,117][INFO ][node                     ] [Space Turnip] stopped
[2016-07-22 09:36:14,117][INFO ][node                     ] [Space Turnip] closing ...
[2016-07-22 09:36:14,124][INFO ][node                     ] [Space Turnip] closed
[2016-07-22 09:36:22,560][INFO ][node                     ] [Primevil] version[2.3.4], pid[1218], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:36:22,561][INFO ][node                     ] [Primevil] initializing ...
[2016-07-22 09:36:23,476][INFO ][plugins                  ] [Primevil] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:36:23,568][INFO ][env                      ] [Primevil] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:36:23,568][INFO ][env                      ] [Primevil] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:36:23,569][WARN ][env                      ] [Primevil] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:36:26,974][INFO ][node                     ] [Primevil] initialized
[2016-07-22 09:36:26,974][INFO ][node                     ] [Primevil] starting ...
[2016-07-22 09:36:27,096][INFO ][transport                ] [Primevil] publish_address {127.0.0.1:9310}, bound_addresses {[fe80::1]:9310}, {[::1]:9310}, {127.0.0.1:9310}
[2016-07-22 09:36:27,100][INFO ][discovery                ] [Primevil] elasticsearch/6eglDmQTSOWzzDFIatEeKA
[2016-07-22 09:36:30,194][INFO ][cluster.service          ] [Siege] added {{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-join(join from node[{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310}])
[2016-07-22 09:36:30,205][INFO ][cluster.service          ] [Myron MacLain] added {{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:30,205][INFO ][cluster.service          ] [Siryn] added {{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:30,210][INFO ][cluster.service          ] [Cloud] added {{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:30,210][INFO ][cluster.service          ] [Jerry Jaxon] added {{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:30,214][INFO ][cluster.service          ] [Red Ghost] added {{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:30,214][INFO ][cluster.service          ] [Joshua Guthrie] added {{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:30,219][INFO ][cluster.service          ] [Outrage] added {{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:30,218][INFO ][cluster.service          ] [Aminedi] added {{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:30,236][INFO ][cluster.service          ] [Primevil] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:30,253][INFO ][cluster.service          ] [Eternal Brain] added {{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:36:30,490][INFO ][http                     ] [Primevil] publish_address {127.0.0.1:9210}, bound_addresses {[fe80::1]:9210}, {[::1]:9210}, {127.0.0.1:9210}
[2016-07-22 09:36:30,491][INFO ][node                     ] [Primevil] started
[2016-07-22 09:37:00,862][INFO ][node                     ] [Mauler] version[2.3.4], pid[1242], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:37:00,863][INFO ][node                     ] [Mauler] initializing ...
[2016-07-22 09:37:01,811][INFO ][plugins                  ] [Mauler] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:37:01,869][INFO ][env                      ] [Mauler] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:37:01,870][INFO ][env                      ] [Mauler] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:37:01,871][WARN ][env                      ] [Mauler] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:37:04,670][INFO ][node                     ] [Mauler] initialized
[2016-07-22 09:37:04,671][INFO ][node                     ] [Mauler] starting ...
[2016-07-22 09:37:04,915][INFO ][transport                ] [Mauler] publish_address {127.0.0.1:9311}, bound_addresses {[fe80::1]:9311}, {[::1]:9311}, {127.0.0.1:9311}
[2016-07-22 09:37:04,922][INFO ][discovery                ] [Mauler] elasticsearch/pc2ZepAzRFu3BVm0pgYzdg
[2016-07-22 09:37:08,038][INFO ][cluster.service          ] [Siege] added {{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-join(join from node[{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311}])
[2016-07-22 09:37:08,041][INFO ][cluster.service          ] [Siryn] added {{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:08,042][INFO ][cluster.service          ] [Cloud] added {{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:08,042][INFO ][cluster.service          ] [Jerry Jaxon] added {{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:08,043][INFO ][cluster.service          ] [Red Ghost] added {{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:08,049][INFO ][cluster.service          ] [Myron MacLain] added {{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:08,051][INFO ][cluster.service          ] [Joshua Guthrie] added {{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:08,057][INFO ][cluster.service          ] [Eternal Brain] added {{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:08,061][INFO ][cluster.service          ] [Outrage] added {{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:08,061][INFO ][cluster.service          ] [Aminedi] added {{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:08,073][INFO ][cluster.service          ] [Mauler] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:08,124][INFO ][cluster.service          ] [Primevil] added {{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:08,300][INFO ][http                     ] [Mauler] publish_address {127.0.0.1:9211}, bound_addresses {[fe80::1]:9211}, {[::1]:9211}, {127.0.0.1:9211}
[2016-07-22 09:37:08,301][INFO ][node                     ] [Mauler] started
[2016-07-22 09:37:15,720][INFO ][node                     ] [Hugh Jones] version[2.3.4], pid[1264], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:37:15,782][INFO ][node                     ] [Hugh Jones] initializing ...
[2016-07-22 09:37:16,809][INFO ][plugins                  ] [Hugh Jones] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:37:16,868][INFO ][env                      ] [Hugh Jones] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:37:16,868][INFO ][env                      ] [Hugh Jones] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:37:16,870][WARN ][env                      ] [Hugh Jones] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:37:19,766][INFO ][node                     ] [Hugh Jones] initialized
[2016-07-22 09:37:19,766][INFO ][node                     ] [Hugh Jones] starting ...
[2016-07-22 09:37:19,954][INFO ][transport                ] [Hugh Jones] publish_address {127.0.0.1:9312}, bound_addresses {[fe80::1]:9312}, {[::1]:9312}, {127.0.0.1:9312}
[2016-07-22 09:37:19,961][INFO ][discovery                ] [Hugh Jones] elasticsearch/2BHKFjIxT1-BoXUEx9d92w
[2016-07-22 09:37:23,073][INFO ][cluster.service          ] [Siege] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-join(join from node[{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312}])
[2016-07-22 09:37:23,087][INFO ][cluster.service          ] [Cloud] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,088][INFO ][cluster.service          ] [Jerry Jaxon] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,095][INFO ][cluster.service          ] [Red Ghost] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,099][INFO ][cluster.service          ] [Myron MacLain] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,101][INFO ][cluster.service          ] [Primevil] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,107][INFO ][cluster.service          ] [Joshua Guthrie] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,108][INFO ][cluster.service          ] [Aminedi] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,108][INFO ][cluster.service          ] [Eternal Brain] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,111][INFO ][cluster.service          ] [Outrage] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,124][INFO ][cluster.service          ] [Siryn] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,127][INFO ][cluster.service          ] [Hugh Jones] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,175][INFO ][cluster.service          ] [Mauler] added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:23,392][INFO ][http                     ] [Hugh Jones] publish_address {127.0.0.1:9212}, bound_addresses {[fe80::1]:9212}, {[::1]:9212}, {127.0.0.1:9212}
[2016-07-22 09:37:23,393][INFO ][node                     ] [Hugh Jones] started
[2016-07-22 09:37:40,204][INFO ][node                     ] [Geiger] version[2.3.4], pid[1290], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:37:40,228][INFO ][node                     ] [Geiger] initializing ...
[2016-07-22 09:37:41,290][INFO ][plugins                  ] [Geiger] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:37:41,364][INFO ][env                      ] [Geiger] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:37:41,365][INFO ][env                      ] [Geiger] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:37:41,366][WARN ][env                      ] [Geiger] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:37:43,889][INFO ][node                     ] [Geiger] initialized
[2016-07-22 09:37:43,889][INFO ][node                     ] [Geiger] starting ...
[2016-07-22 09:37:44,035][INFO ][transport                ] [Geiger] publish_address {127.0.0.1:9313}, bound_addresses {[fe80::1]:9313}, {[::1]:9313}, {127.0.0.1:9313}
[2016-07-22 09:37:44,041][INFO ][discovery                ] [Geiger] elasticsearch/PMeMoLg4TEG0FWdOPXOXvw
[2016-07-22 09:37:47,145][INFO ][cluster.service          ] [Siege] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-join(join from node[{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313}])
[2016-07-22 09:37:47,165][INFO ][cluster.service          ] [Jerry Jaxon] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,165][INFO ][cluster.service          ] [Siryn] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,167][INFO ][cluster.service          ] [Myron MacLain] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,170][INFO ][cluster.service          ] [Joshua Guthrie] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,173][INFO ][cluster.service          ] [Mauler] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,174][INFO ][cluster.service          ] [Cloud] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,177][INFO ][cluster.service          ] [Eternal Brain] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,183][INFO ][cluster.service          ] [Outrage] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,184][INFO ][cluster.service          ] [Primevil] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,189][INFO ][cluster.service          ] [Geiger] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,189][INFO ][cluster.service          ] [Red Ghost] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,191][INFO ][cluster.service          ] [Aminedi] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,196][INFO ][cluster.service          ] [Hugh Jones] added {{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:37:47,235][WARN ][cluster.service          ] [Hugh Jones] failed to connect to node [{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313}]
ConnectTransportException[[Geiger][127.0.0.1:9313] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:987)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:37:47,247][WARN ][cluster.service          ] [Primevil] failed to connect to node [{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313}]
ConnectTransportException[[Geiger][127.0.0.1:9313] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:37:47,461][INFO ][http                     ] [Geiger] publish_address {127.0.0.1:9213}, bound_addresses {[fe80::1]:9213}, {[::1]:9213}, {127.0.0.1:9213}
[2016-07-22 09:37:47,461][INFO ][node                     ] [Geiger] started
[2016-07-22 09:37:48,268][WARN ][cluster.service          ] [Joshua Guthrie] failed to connect to node [{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313}]
ConnectTransportException[[Geiger][127.0.0.1:9313] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:39:26,871][INFO ][node                     ] [Giant-Man] version[2.3.4], pid[1322], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:39:27,023][INFO ][node                     ] [Giant-Man] initializing ...
[2016-07-22 09:39:27,920][INFO ][plugins                  ] [Giant-Man] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:39:27,977][INFO ][env                      ] [Giant-Man] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:39:27,977][INFO ][env                      ] [Giant-Man] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:39:27,978][WARN ][env                      ] [Giant-Man] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:39:31,143][INFO ][node                     ] [Giant-Man] initialized
[2016-07-22 09:39:31,143][INFO ][node                     ] [Giant-Man] starting ...
[2016-07-22 09:39:31,299][INFO ][transport                ] [Giant-Man] publish_address {127.0.0.1:9314}, bound_addresses {[fe80::1]:9314}, {[::1]:9314}, {127.0.0.1:9314}
[2016-07-22 09:39:31,304][INFO ][discovery                ] [Giant-Man] elasticsearch/MXO4JMzzTnqLZNSMtzTdFA
[2016-07-22 09:39:34,414][INFO ][cluster.service          ] [Siege] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-join(join from node[{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}])
[2016-07-22 09:39:34,425][INFO ][cluster.service          ] [Siryn] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,426][INFO ][cluster.service          ] [Myron MacLain] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,427][INFO ][cluster.service          ] [Jerry Jaxon] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,428][INFO ][cluster.service          ] [Joshua Guthrie] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,431][INFO ][cluster.service          ] [Cloud] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,431][INFO ][cluster.service          ] [Mauler] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,433][INFO ][cluster.service          ] [Red Ghost] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,438][INFO ][cluster.service          ] [Eternal Brain] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,440][INFO ][cluster.service          ] [Primevil] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,438][INFO ][cluster.service          ] [Outrage] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,438][INFO ][cluster.service          ] [Aminedi] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,436][INFO ][cluster.service          ] [Hugh Jones] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,443][INFO ][cluster.service          ] [Giant-Man] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,491][WARN ][cluster.service          ] [Jerry Jaxon] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:39:34,526][WARN ][cluster.service          ] [Primevil] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:39:34,515][WARN ][cluster.service          ] [Mauler] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1014)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:39:34,527][WARN ][cluster.service          ] [Myron MacLain] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:39:34,541][INFO ][cluster.service          ] [Geiger] added {{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:39:34,749][INFO ][http                     ] [Giant-Man] publish_address {127.0.0.1:9214}, bound_addresses {[fe80::1]:9214}, {[::1]:9214}, {127.0.0.1:9214}
[2016-07-22 09:39:34,750][INFO ][node                     ] [Giant-Man] started
[2016-07-22 09:39:35,517][WARN ][cluster.service          ] [Eternal Brain] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1014)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:39:35,516][WARN ][cluster.service          ] [Aminedi] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:39:35,514][WARN ][cluster.service          ] [Red Ghost] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1014)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:40:23,373][INFO ][node                     ] [Jimaine Szardos] version[2.3.4], pid[1347], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:40:23,393][INFO ][node                     ] [Jimaine Szardos] initializing ...
[2016-07-22 09:40:24,294][INFO ][plugins                  ] [Jimaine Szardos] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:40:24,459][INFO ][env                      ] [Jimaine Szardos] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:40:24,459][INFO ][env                      ] [Jimaine Szardos] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:40:24,460][WARN ][env                      ] [Jimaine Szardos] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:40:27,423][INFO ][node                     ] [Jimaine Szardos] initialized
[2016-07-22 09:40:27,423][INFO ][node                     ] [Jimaine Szardos] starting ...
[2016-07-22 09:40:27,621][INFO ][transport                ] [Jimaine Szardos] publish_address {127.0.0.1:9315}, bound_addresses {[fe80::1]:9315}, {[::1]:9315}, {127.0.0.1:9315}
[2016-07-22 09:40:27,628][INFO ][discovery                ] [Jimaine Szardos] elasticsearch/fPTuo0I5T_yORPS1MOBRaw
[2016-07-22 09:40:30,779][INFO ][cluster.service          ] [Siege] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-join(join from node[{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}])
[2016-07-22 09:40:30,782][INFO ][cluster.service          ] [Siryn] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,782][INFO ][cluster.service          ] [Jerry Jaxon] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,784][INFO ][cluster.service          ] [Myron MacLain] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,784][INFO ][cluster.service          ] [Joshua Guthrie] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,787][INFO ][cluster.service          ] [Eternal Brain] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,787][INFO ][cluster.service          ] [Mauler] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,790][INFO ][cluster.service          ] [Jimaine Szardos] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,790][INFO ][cluster.service          ] [Outrage] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,790][INFO ][cluster.service          ] [Cloud] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,802][INFO ][cluster.service          ] [Primevil] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,803][INFO ][cluster.service          ] [Geiger] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,800][INFO ][cluster.service          ] [Hugh Jones] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,808][INFO ][cluster.service          ] [Aminedi] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,793][INFO ][cluster.service          ] [Red Ghost] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:30,810][INFO ][cluster.service          ] [Giant-Man] added {{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:40:31,009][WARN ][cluster.service          ] [Eternal Brain] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1014)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:40:31,009][WARN ][cluster.service          ] [Red Ghost] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:40:31,016][WARN ][cluster.service          ] [Mauler] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:40:31,012][WARN ][cluster.service          ] [Joshua Guthrie] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:40:31,013][WARN ][cluster.service          ] [Giant-Man] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:40:31,020][WARN ][cluster.service          ] [Aminedi] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:40:31,035][WARN ][cluster.service          ] [Primevil] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:40:31,355][INFO ][http                     ] [Jimaine Szardos] publish_address {127.0.0.1:9215}, bound_addresses {[fe80::1]:9215}, {[::1]:9215}, {127.0.0.1:9215}
[2016-07-22 09:40:31,356][INFO ][node                     ] [Jimaine Szardos] started
[2016-07-22 09:40:31,906][WARN ][cluster.service          ] [Siryn] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:40,363][INFO ][node                     ] [Xandu] version[2.3.4], pid[1375], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 09:49:40,377][INFO ][node                     ] [Xandu] initializing ...
[2016-07-22 09:49:41,357][INFO ][plugins                  ] [Xandu] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 09:49:41,456][INFO ][env                      ] [Xandu] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [255.5gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 09:49:41,456][INFO ][env                      ] [Xandu] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 09:49:41,457][WARN ][env                      ] [Xandu] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 09:49:44,917][INFO ][node                     ] [Xandu] initialized
[2016-07-22 09:49:44,917][INFO ][node                     ] [Xandu] starting ...
[2016-07-22 09:49:45,083][INFO ][transport                ] [Xandu] publish_address {127.0.0.1:9316}, bound_addresses {[fe80::1]:9316}, {[::1]:9316}, {127.0.0.1:9316}
[2016-07-22 09:49:45,089][INFO ][discovery                ] [Xandu] elasticsearch/EGvpHQ-qTkWIN0ACb0dceQ
[2016-07-22 09:49:48,241][INFO ][cluster.service          ] [Siege] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-join(join from node[{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}])
[2016-07-22 09:49:48,244][INFO ][cluster.service          ] [Myron MacLain] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,244][INFO ][cluster.service          ] [Jerry Jaxon] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,244][INFO ][cluster.service          ] [Siryn] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,245][INFO ][cluster.service          ] [Joshua Guthrie] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,246][INFO ][cluster.service          ] [Mauler] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,249][INFO ][cluster.service          ] [Outrage] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,252][INFO ][cluster.service          ] [Giant-Man] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,255][INFO ][cluster.service          ] [Cloud] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,258][INFO ][cluster.service          ] [Geiger] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,261][INFO ][cluster.service          ] [Primevil] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,262][INFO ][cluster.service          ] [Eternal Brain] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,253][INFO ][cluster.service          ] [Red Ghost] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,259][INFO ][cluster.service          ] [Aminedi] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,257][INFO ][cluster.service          ] [Hugh Jones] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,277][INFO ][cluster.service          ] [Xandu] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,321][INFO ][cluster.service          ] [Jimaine Szardos] added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 09:49:48,439][WARN ][cluster.service          ] [Jerry Jaxon] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:48,578][WARN ][cluster.service          ] [Geiger] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:48,634][WARN ][cluster.service          ] [Aminedi] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:48,427][WARN ][cluster.service          ] [Mauler] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:48,691][WARN ][cluster.service          ] [Jimaine Szardos] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:48,703][WARN ][cluster.service          ] [Primevil] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1014)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:48,709][WARN ][cluster.service          ] [Eternal Brain] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:48,427][WARN ][cluster.service          ] [Red Ghost] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:48,731][WARN ][cluster.service          ] [Outrage] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:48,841][WARN ][cluster.service          ] [Giant-Man] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:48,947][WARN ][cluster.service          ] [Cloud] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 09:49:49,303][INFO ][http                     ] [Xandu] publish_address {127.0.0.1:9216}, bound_addresses {[fe80::1]:9216}, {[::1]:9216}, {127.0.0.1:9216}
[2016-07-22 09:49:49,303][INFO ][node                     ] [Xandu] started
[2016-07-22 10:04:22,311][INFO ][node                     ] [Cheetah] version[2.3.4], pid[1431], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 10:04:22,400][INFO ][node                     ] [Cheetah] initializing ...
[2016-07-22 10:04:23,188][INFO ][plugins                  ] [Cheetah] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 10:04:23,239][INFO ][env                      ] [Cheetah] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [254.4gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 10:04:23,239][INFO ][env                      ] [Cheetah] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 10:04:23,240][WARN ][env                      ] [Cheetah] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 10:04:23,870][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:04:25,694][INFO ][node                     ] [Cheetah] initialized
[2016-07-22 10:04:25,694][INFO ][node                     ] [Cheetah] starting ...
[2016-07-22 10:04:25,724][ERROR][bootstrap                ] [Cheetah] Exception
org.jboss.netty.channel.ChannelException: Failed to create a selector.
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:362)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.<init>(AbstractNioWorker.java:52)
	at org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:45)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.newWorker(NioWorkerPool.java:44)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.newWorker(NioWorkerPool.java:28)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.init(AbstractNioWorkerPool.java:80)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:39)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:33)
	at org.elasticsearch.transport.netty.NettyTransport.createClientBootstrap(NettyTransport.java:346)
	at org.elasticsearch.transport.netty.NettyTransport.doStart(NettyTransport.java:279)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.transport.TransportService.doStart(TransportService.java:182)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.node.Node.start(Node.java:278)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:206)
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:272)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)
Caused by: java.io.IOException: Too many open files in system
	at sun.nio.ch.IOUtil.makePipe(Native Method)
	at sun.nio.ch.KQueueSelectorImpl.<init>(KQueueSelectorImpl.java:84)
	at sun.nio.ch.KQueueSelectorProvider.openSelector(KQueueSelectorProvider.java:42)
	at java.nio.channels.Selector.open(Selector.java:227)
	at org.jboss.netty.channel.socket.nio.SelectorUtil.open(SelectorUtil.java:63)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:360)
	... 17 more
[2016-07-22 10:04:25,730][INFO ][node                     ] [Cheetah] stopping ...
[2016-07-22 10:04:25,733][INFO ][node                     ] [Cheetah] stopped
[2016-07-22 10:04:25,733][INFO ][node                     ] [Cheetah] closing ...
[2016-07-22 10:04:25,740][INFO ][node                     ] [Cheetah] closed
[2016-07-22 10:05:45,806][INFO ][node                     ] [Cain] version[2.3.4], pid[1456], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 10:05:45,826][INFO ][node                     ] [Cain] initializing ...
[2016-07-22 10:05:46,852][ERROR][bootstrap                ] Exception
java.lang.IllegalStateException: failed to load bundle [file:/Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/modules/reindex/reindex-2.3.4.jar] due to jar hell
	at org.elasticsearch.plugins.PluginsService.loadBundles(PluginsService.java:421)
	at org.elasticsearch.plugins.PluginsService.<init>(PluginsService.java:115)
	at org.elasticsearch.node.Node.<init>(Node.java:158)
	at org.elasticsearch.node.Node.<init>(Node.java:140)
	at org.elasticsearch.node.NodeBuilder.build(NodeBuilder.java:143)
	at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:178)
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:270)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)
Caused by: java.io.FileNotFoundException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/modules/reindex/reindex-2.3.4.jar (Too many open files in system)
	at java.util.zip.ZipFile.open(Native Method)
	at java.util.zip.ZipFile.<init>(ZipFile.java:219)
	at java.util.zip.ZipFile.<init>(ZipFile.java:149)
	at java.util.jar.JarFile.<init>(JarFile.java:166)
	at java.util.jar.JarFile.<init>(JarFile.java:103)
	at org.elasticsearch.bootstrap.JarHell.checkJarHell(JarHell.java:174)
	at org.elasticsearch.plugins.PluginsService.loadBundles(PluginsService.java:419)
	... 7 more
[2016-07-22 10:08:12,596][INFO ][node                     ] [Captain Savage] version[2.3.4], pid[1570], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 10:08:12,612][INFO ][node                     ] [Captain Savage] initializing ...
[2016-07-22 10:08:13,577][INFO ][plugins                  ] [Captain Savage] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 10:08:13,618][INFO ][env                      ] [Captain Savage] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [254.4gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 10:08:13,618][INFO ][env                      ] [Captain Savage] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 10:08:13,619][WARN ][env                      ] [Captain Savage] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 10:08:16,614][INFO ][node                     ] [Captain Savage] initialized
[2016-07-22 10:08:16,615][INFO ][node                     ] [Captain Savage] starting ...
[2016-07-22 10:08:16,769][INFO ][transport                ] [Captain Savage] publish_address {127.0.0.1:9317}, bound_addresses {[fe80::1]:9317}, {[::1]:9317}, {127.0.0.1:9317}
[2016-07-22 10:08:16,775][INFO ][discovery                ] [Captain Savage] elasticsearch/3vgIaYvmTtyZZzNviESB5A
[2016-07-22 10:08:20,030][INFO ][cluster.service          ] [Siege] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-join(join from node[{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}])
[2016-07-22 10:08:20,039][INFO ][cluster.service          ] [Siryn] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,042][INFO ][cluster.service          ] [Jimaine Szardos] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,044][INFO ][cluster.service          ] [Joshua Guthrie] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,055][INFO ][cluster.service          ] [Myron MacLain] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,055][INFO ][cluster.service          ] [Cloud] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,065][INFO ][cluster.service          ] [Red Ghost] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,070][INFO ][cluster.service          ] [Outrage] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,074][INFO ][cluster.service          ] [Mauler] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,079][INFO ][cluster.service          ] [Geiger] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,086][INFO ][cluster.service          ] [Eternal Brain] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,095][INFO ][cluster.service          ] [Giant-Man] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,087][INFO ][cluster.service          ] [Hugh Jones] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,107][INFO ][cluster.service          ] [Captain Savage] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,106][INFO ][cluster.service          ] [Primevil] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,116][INFO ][cluster.service          ] [Xandu] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,150][WARN ][cluster.service          ] [Giant-Man] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:974)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,151][WARN ][cluster.service          ] [Primevil] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:974)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,158][WARN ][cluster.service          ] [Xandu] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:974)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,171][WARN ][gateway                  ] [Giant-Man] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/14/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,172][WARN ][gateway                  ] [Primevil] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/10/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,176][WARN ][cluster.service          ] [Eternal Brain] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:971)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,159][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,180][WARN ][cluster.service          ] [Jimaine Szardos] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:971)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,178][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,172][WARN ][cluster.service          ] [Hugh Jones] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:974)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,184][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312}]
ConnectTransportException[[Hugh Jones][127.0.0.1:9312] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:974)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,189][WARN ][gateway                  ] [Eternal Brain] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/9/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,189][WARN ][gateway                  ] [Hugh Jones] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/12/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,190][WARN ][gateway                  ] [Jimaine Szardos] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/15/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,165][WARN ][cluster.service          ] [Joshua Guthrie] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:974)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,191][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305}]
ConnectTransportException[[Outrage][127.0.0.1:9305] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,076][INFO ][cluster.service          ] [Aminedi] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,196][WARN ][gateway                  ] [Joshua Guthrie] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/2/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,072][INFO ][cluster.service          ] [Jerry Jaxon] added {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,194][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313}]
ConnectTransportException[[Geiger][127.0.0.1:9313] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,197][WARN ][cluster.service          ] [Aminedi] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,199][WARN ][cluster.service          ] [Jerry Jaxon] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,203][WARN ][gateway                  ] [Aminedi] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/1/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,199][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310}]
ConnectTransportException[[Primevil][127.0.0.1:9310] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,207][WARN ][gateway                  ] [Jerry Jaxon] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/3/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,179][WARN ][cluster.service          ] [Mauler] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,208][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307}]
ConnectTransportException[[Siryn][127.0.0.1:9307] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,177][WARN ][cluster.service          ] [Geiger] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:971)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,214][WARN ][gateway                  ] [Mauler] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/11/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,212][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303}]
ConnectTransportException[[Jerry Jaxon][127.0.0.1:9303] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,217][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301}]
ConnectTransportException[[Aminedi][127.0.0.1:9301] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,219][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308}]
ConnectTransportException[[Cloud][127.0.0.1:9308] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,168][WARN ][cluster.service          ] [Outrage] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:971)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,169][WARN ][cluster.service          ] [Myron MacLain] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:971)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,224][WARN ][gateway                  ] [Outrage] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/5/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,181][WARN ][cluster.service          ] [Red Ghost] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:971)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,229][WARN ][gateway                  ] [Myron MacLain] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/4/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,229][WARN ][gateway                  ] [Geiger] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/13/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,213][WARN ][cluster.service          ] [Cloud] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:971)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,237][WARN ][gateway                  ] [Red Ghost] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/6/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,220][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309}]
ConnectTransportException[[Eternal Brain][127.0.0.1:9309] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,242][WARN ][gateway                  ] [Cloud] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/8/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,248][WARN ][gateway                  ] [Xandu] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/16/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,251][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,254][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306}]
ConnectTransportException[[Red Ghost][127.0.0.1:9306] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,256][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,257][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304}]
ConnectTransportException[[Myron MacLain][127.0.0.1:9304] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,262][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,268][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,280][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302}]
ConnectTransportException[[Joshua Guthrie][127.0.0.1:9302] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,284][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,282][WARN ][cluster.service          ] [Captain Savage] failed to connect to node [{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311}]
ConnectTransportException[[Mauler][127.0.0.1:9311] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:20,273][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,472][WARN ][gateway                  ] [Captain Savage] [.kibana]: failed to write index state
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/17/indices/.kibana/_state/state-0.st.tmp: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434)
	at java.nio.file.Files.newOutputStream(Files.java:216)
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:112)
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:135)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:160)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,473][WARN ][gateway                  ] [Captain Savage] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/17/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:20,476][ERROR][bootstrap                ] [Captain Savage] Exception
org.jboss.netty.channel.ChannelException: Failed to create a selector.
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:362)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.<init>(AbstractNioWorker.java:52)
	at org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:45)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.newWorker(NioWorkerPool.java:44)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.newWorker(NioWorkerPool.java:28)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.init(AbstractNioWorkerPool.java:80)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:39)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:33)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:149)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:131)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.doStart(NettyHttpServerTransport.java:251)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.http.HttpServer.doStart(HttpServer.java:92)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.node.Node.start(Node.java:289)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:206)
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:272)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)
Caused by: java.io.IOException: Too many open files in system
	at sun.nio.ch.IOUtil.makePipe(Native Method)
	at sun.nio.ch.KQueueSelectorImpl.<init>(KQueueSelectorImpl.java:84)
	at sun.nio.ch.KQueueSelectorProvider.openSelector(KQueueSelectorProvider.java:42)
	at java.nio.channels.Selector.open(Selector.java:227)
	at org.jboss.netty.channel.socket.nio.SelectorUtil.open(SelectorUtil.java:63)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:360)
	... 18 more
[2016-07-22 10:08:20,483][INFO ][node                     ] [Captain Savage] stopping ...
[2016-07-22 10:08:20,485][INFO ][discovery.zen            ] [Captain Savage] failed to send join request to master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}], reason [IllegalStateException[Future got interrupted]; nested: InterruptedException; ]
[2016-07-22 10:08:20,522][WARN ][cluster.service          ] [Siryn] failed to connect to node [{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Captain Savage][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1014)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:20,550][DEBUG][action.admin.cluster.node.stats] [Siege] failed to execute on node [3vgIaYvmTtyZZzNviESB5A]
SendRequestTransportException[[Captain Savage][127.0.0.1:9317][cluster:monitor/nodes/stats[n]]]; nested: NodeNotConnectedException[[Captain Savage][127.0.0.1:9317] Node not connected];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:340)
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.start(TransportNodesAction.java:164)
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$100(TransportNodesAction.java:106)
	at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:76)
	at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:46)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:137)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:85)
	at org.elasticsearch.cluster.InternalClusterInfoService.updateNodeStats(InternalClusterInfoService.java:289)
	at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:325)
	at org.elasticsearch.cluster.InternalClusterInfoService.maybeRefresh(InternalClusterInfoService.java:310)
	at org.elasticsearch.cluster.InternalClusterInfoService.access$600(InternalClusterInfoService.java:69)
	at org.elasticsearch.cluster.InternalClusterInfoService$2.run(InternalClusterInfoService.java:202)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: NodeNotConnectedException[[Captain Savage][127.0.0.1:9317] Node not connected]
	at org.elasticsearch.transport.netty.NettyTransport.nodeChannel(NettyTransport.java:1132)
	at org.elasticsearch.transport.netty.NettyTransport.sendRequest(NettyTransport.java:819)
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:329)
	... 14 more
[2016-07-22 10:08:20,556][INFO ][cluster.service          ] [Siege] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-node_left({Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317})
[2016-07-22 10:08:20,558][INFO ][cluster.service          ] [Myron MacLain] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,564][INFO ][cluster.service          ] [Siryn] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,563][INFO ][cluster.service          ] [Cloud] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,566][INFO ][cluster.service          ] [Primevil] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,563][INFO ][cluster.service          ] [Giant-Man] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,561][INFO ][cluster.service          ] [Red Ghost] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,567][INFO ][cluster.service          ] [Jimaine Szardos] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,568][INFO ][cluster.service          ] [Hugh Jones] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,568][INFO ][cluster.service          ] [Outrage] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,569][INFO ][cluster.service          ] [Joshua Guthrie] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,569][INFO ][cluster.service          ] [Jerry Jaxon] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,570][INFO ][cluster.service          ] [Eternal Brain] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,565][INFO ][cluster.service          ] [Mauler] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,562][INFO ][cluster.service          ] [Geiger] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,574][INFO ][cluster.service          ] [Xandu] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:20,562][INFO ][cluster.service          ] [Aminedi] removed {{Captain Savage}{3vgIaYvmTtyZZzNviESB5A}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:21,192][INFO ][node                     ] [Captain Savage] stopped
[2016-07-22 10:08:21,193][INFO ][node                     ] [Captain Savage] closing ...
[2016-07-22 10:08:21,202][INFO ][node                     ] [Captain Savage] closed
[2016-07-22 10:08:22,797][INFO ][node                     ] [Jackdaw] version[2.3.4], pid[1593], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 10:08:22,798][INFO ][node                     ] [Jackdaw] initializing ...
[2016-07-22 10:08:23,756][INFO ][plugins                  ] [Jackdaw] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 10:08:23,925][INFO ][env                      ] [Jackdaw] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [254.4gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 10:08:23,925][INFO ][env                      ] [Jackdaw] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 10:08:23,926][WARN ][env                      ] [Jackdaw] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 10:08:26,660][INFO ][node                     ] [Jackdaw] initialized
[2016-07-22 10:08:26,661][INFO ][node                     ] [Jackdaw] starting ...
[2016-07-22 10:08:26,811][INFO ][transport                ] [Jackdaw] publish_address {127.0.0.1:9317}, bound_addresses {[fe80::1]:9317}, {[::1]:9317}, {127.0.0.1:9317}
[2016-07-22 10:08:26,835][INFO ][discovery                ] [Jackdaw] elasticsearch/YzBnq4ilQpeg5lTvEGk-Tg
[2016-07-22 10:08:29,979][INFO ][cluster.service          ] [Siege] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-join(join from node[{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}])
[2016-07-22 10:08:29,983][INFO ][cluster.service          ] [Geiger] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:29,986][INFO ][cluster.service          ] [Siryn] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:29,988][INFO ][cluster.service          ] [Primevil] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:29,990][INFO ][cluster.service          ] [Jerry Jaxon] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:29,992][INFO ][cluster.service          ] [Myron MacLain] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:29,993][INFO ][cluster.service          ] [Joshua Guthrie] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:29,993][INFO ][cluster.service          ] [Jackdaw] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:29,995][INFO ][cluster.service          ] [Jimaine Szardos] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:29,996][INFO ][cluster.service          ] [Aminedi] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:29,997][INFO ][cluster.service          ] [Xandu] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:29,998][INFO ][cluster.service          ] [Eternal Brain] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:29,999][INFO ][cluster.service          ] [Mauler] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,002][INFO ][cluster.service          ] [Giant-Man] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,003][INFO ][cluster.service          ] [Outrage] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,010][INFO ][cluster.service          ] [Cloud] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,014][INFO ][cluster.service          ] [Red Ghost] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,012][INFO ][cluster.service          ] [Hugh Jones] added {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,071][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:30,072][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:30,072][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310}]
ConnectTransportException[[Primevil][127.0.0.1:9310] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:974)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,081][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313}]
ConnectTransportException[[Geiger][127.0.0.1:9313] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,083][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312}]
ConnectTransportException[[Hugh Jones][127.0.0.1:9312] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,084][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306}]
ConnectTransportException[[Red Ghost][127.0.0.1:9306] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,085][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305}]
ConnectTransportException[[Outrage][127.0.0.1:9305] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,086][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308}]
ConnectTransportException[[Cloud][127.0.0.1:9308] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,088][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,088][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301}]
ConnectTransportException[[Aminedi][127.0.0.1:9301] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,090][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,091][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:30,092][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311}]
ConnectTransportException[[Mauler][127.0.0.1:9311] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,092][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:30,093][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:30,093][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302}]
ConnectTransportException[[Joshua Guthrie][127.0.0.1:9302] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,095][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:30,095][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,097][WARN ][cluster.service          ] [Jackdaw] failed to connect to node [{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309}]
ConnectTransportException[[Eternal Brain][127.0.0.1:9309] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:08:30,097][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:30,109][WARN ][gateway                  ] [Jackdaw] [_global]: failed to write global state
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/17/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:525)
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:224)
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:103)
	at org.elasticsearch.gateway.MetaStateService.writeGlobalState(MetaStateService.java:149)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:148)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:30,110][WARN ][gateway                  ] [Jackdaw] [.kibana]: failed to write index state
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/17/indices/.kibana/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:525)
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:224)
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:103)
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:135)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:160)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:30,111][WARN ][gateway                  ] [Jackdaw] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/17/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:08:30,112][ERROR][bootstrap                ] [Jackdaw] Exception
org.jboss.netty.channel.ChannelException: Failed to create a selector.
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:362)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.<init>(AbstractNioWorker.java:52)
	at org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:45)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.newWorker(NioWorkerPool.java:44)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.newWorker(NioWorkerPool.java:28)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.init(AbstractNioWorkerPool.java:80)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:39)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:33)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:149)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:131)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.doStart(NettyHttpServerTransport.java:251)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.http.HttpServer.doStart(HttpServer.java:92)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.node.Node.start(Node.java:289)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:206)
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:272)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)
Caused by: java.io.IOException: Too many open files in system
	at sun.nio.ch.IOUtil.makePipe(Native Method)
	at sun.nio.ch.KQueueSelectorImpl.<init>(KQueueSelectorImpl.java:84)
	at sun.nio.ch.KQueueSelectorProvider.openSelector(KQueueSelectorProvider.java:42)
	at java.nio.channels.Selector.open(Selector.java:227)
	at org.jboss.netty.channel.socket.nio.SelectorUtil.open(SelectorUtil.java:63)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:360)
	... 18 more
[2016-07-22 10:08:30,118][INFO ][node                     ] [Jackdaw] stopping ...
[2016-07-22 10:08:30,121][INFO ][discovery.zen            ] [Jackdaw] failed to send join request to master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}], reason [IllegalStateException[Future got interrupted]; nested: InterruptedException; ]
[2016-07-22 10:08:30,151][WARN ][cluster.service          ] [Hugh Jones] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:987)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,151][WARN ][cluster.service          ] [Red Ghost] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,166][WARN ][cluster.service          ] [Joshua Guthrie] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,178][WARN ][cluster.service          ] [Giant-Man] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:987)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,207][WARN ][cluster.service          ] [Siryn] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,259][WARN ][cluster.service          ] [Geiger] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,261][WARN ][cluster.service          ] [Primevil] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,183][WARN ][cluster.service          ] [Aminedi] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:987)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,259][WARN ][cluster.service          ] [Jerry Jaxon] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,277][WARN ][cluster.service          ] [Mauler] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,151][WARN ][cluster.service          ] [Eternal Brain] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,226][WARN ][cluster.service          ] [Cloud] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,276][WARN ][cluster.service          ] [Jimaine Szardos] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,260][WARN ][cluster.service          ] [Outrage] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,291][WARN ][cluster.service          ] [Xandu] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:987)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,283][WARN ][cluster.service          ] [Myron MacLain] failed to connect to node [{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Jackdaw][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:08:30,301][INFO ][cluster.service          ] [Siege] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-node_left({Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317})
[2016-07-22 10:08:30,306][INFO ][cluster.service          ] [Giant-Man] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,308][INFO ][cluster.service          ] [Joshua Guthrie] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,310][INFO ][cluster.service          ] [Aminedi] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,310][INFO ][cluster.service          ] [Myron MacLain] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,310][INFO ][cluster.service          ] [Jimaine Szardos] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,309][INFO ][cluster.service          ] [Xandu] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,305][INFO ][cluster.service          ] [Mauler] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,315][INFO ][cluster.service          ] [Outrage] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,316][DEBUG][action.admin.cluster.node.stats] [Siege] failed to execute on node [YzBnq4ilQpeg5lTvEGk-Tg]
SendRequestTransportException[[Jackdaw][127.0.0.1:9317][cluster:monitor/nodes/stats[n]]]; nested: NodeNotConnectedException[[Jackdaw][127.0.0.1:9317] Node not connected];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:340)
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.start(TransportNodesAction.java:164)
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$100(TransportNodesAction.java:106)
	at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:76)
	at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:46)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:137)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:85)
	at org.elasticsearch.cluster.InternalClusterInfoService.updateNodeStats(InternalClusterInfoService.java:289)
	at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:325)
	at org.elasticsearch.cluster.InternalClusterInfoService.maybeRefresh(InternalClusterInfoService.java:310)
	at org.elasticsearch.cluster.InternalClusterInfoService.access$600(InternalClusterInfoService.java:69)
	at org.elasticsearch.cluster.InternalClusterInfoService$2.run(InternalClusterInfoService.java:202)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: NodeNotConnectedException[[Jackdaw][127.0.0.1:9317] Node not connected]
	at org.elasticsearch.transport.netty.NettyTransport.nodeChannel(NettyTransport.java:1132)
	at org.elasticsearch.transport.netty.NettyTransport.sendRequest(NettyTransport.java:819)
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:329)
	... 14 more
[2016-07-22 10:08:30,317][INFO ][cluster.service          ] [Eternal Brain] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,321][INFO ][cluster.service          ] [Cloud] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,321][INFO ][cluster.service          ] [Siryn] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,323][INFO ][cluster.service          ] [Red Ghost] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,323][INFO ][cluster.service          ] [Hugh Jones] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,311][INFO ][cluster.service          ] [Primevil] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,333][INFO ][cluster.service          ] [Jerry Jaxon] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:30,334][INFO ][cluster.service          ] [Geiger] removed {{Jackdaw}{YzBnq4ilQpeg5lTvEGk-Tg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:08:31,091][INFO ][node                     ] [Jackdaw] stopped
[2016-07-22 10:08:31,091][INFO ][node                     ] [Jackdaw] closing ...
[2016-07-22 10:08:31,098][INFO ][node                     ] [Jackdaw] closed
[2016-07-22 10:09:26,535][INFO ][node                     ] [Living Planet] version[2.3.4], pid[1634], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 10:09:26,536][INFO ][node                     ] [Living Planet] initializing ...
[2016-07-22 10:09:27,636][INFO ][plugins                  ] [Living Planet] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 10:09:27,698][INFO ][env                      ] [Living Planet] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [254.4gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 10:09:27,698][INFO ][env                      ] [Living Planet] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 10:09:27,699][WARN ][env                      ] [Living Planet] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 10:09:30,815][INFO ][node                     ] [Living Planet] initialized
[2016-07-22 10:09:30,832][INFO ][node                     ] [Living Planet] starting ...
[2016-07-22 10:09:31,003][INFO ][transport                ] [Living Planet] publish_address {127.0.0.1:9317}, bound_addresses {[fe80::1]:9317}, {[::1]:9317}, {127.0.0.1:9317}
[2016-07-22 10:09:31,013][INFO ][discovery                ] [Living Planet] elasticsearch/x98ZBccLSC6zXqLQItybNg
[2016-07-22 10:09:34,120][INFO ][cluster.service          ] [Siege] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-join(join from node[{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}])
[2016-07-22 10:09:34,123][INFO ][cluster.service          ] [Siryn] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,127][INFO ][cluster.service          ] [Jerry Jaxon] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,129][INFO ][cluster.service          ] [Xandu] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,130][INFO ][cluster.service          ] [Geiger] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,130][INFO ][cluster.service          ] [Myron MacLain] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,131][INFO ][cluster.service          ] [Joshua Guthrie] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,132][INFO ][cluster.service          ] [Jimaine Szardos] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,132][INFO ][cluster.service          ] [Aminedi] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,132][INFO ][cluster.service          ] [Primevil] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,134][INFO ][cluster.service          ] [Eternal Brain] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,134][INFO ][cluster.service          ] [Mauler] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,143][INFO ][cluster.service          ] [Cloud] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,136][INFO ][cluster.service          ] [Outrage] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,139][INFO ][cluster.service          ] [Red Ghost] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,137][INFO ][cluster.service          ] [Giant-Man] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,131][INFO ][cluster.service          ] [Living Planet] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,139][INFO ][cluster.service          ] [Hugh Jones] added {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,191][WARN ][cluster.service          ] [Jerry Jaxon] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,222][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:09:34,223][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309}]
ConnectTransportException[[Eternal Brain][127.0.0.1:9309] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:974)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,227][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:09:34,225][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:09:34,227][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310}]
ConnectTransportException[[Primevil][127.0.0.1:9310] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,230][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:09:34,229][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301}]
ConnectTransportException[[Aminedi][127.0.0.1:9301] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,231][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,232][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:09:34,233][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:09:34,233][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302}]
ConnectTransportException[[Joshua Guthrie][127.0.0.1:9302] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,234][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313}]
ConnectTransportException[[Geiger][127.0.0.1:9313] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,235][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307}]
ConnectTransportException[[Siryn][127.0.0.1:9307] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,236][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311}]
ConnectTransportException[[Mauler][127.0.0.1:9311] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,237][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305}]
ConnectTransportException[[Outrage][127.0.0.1:9305] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,244][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312}]
ConnectTransportException[[Hugh Jones][127.0.0.1:9312] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,245][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,249][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306}]
ConnectTransportException[[Red Ghost][127.0.0.1:9306] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,251][WARN ][cluster.service          ] [Living Planet] failed to connect to node [{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303}]
ConnectTransportException[[Jerry Jaxon][127.0.0.1:9303] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:09:34,268][WARN ][gateway                  ] [Living Planet] [_global]: failed to write global state
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/17/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:525)
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:224)
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:103)
	at org.elasticsearch.gateway.MetaStateService.writeGlobalState(MetaStateService.java:149)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:148)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:09:34,270][WARN ][gateway                  ] [Living Planet] [.kibana]: failed to write index state
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/17/indices/.kibana/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:525)
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:224)
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:103)
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:135)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:160)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:09:34,270][WARN ][gateway                  ] [Living Planet] failed to list dangling indices
java.nio.file.FileSystemException: /Users/dmitriy.turovtsov/master-git/es-book-example/elasticsearch-2.3.4/data/elasticsearch/nodes/17/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.elasticsearch.env.NodeEnvironment.findAllIndices(NodeEnvironment.java:692)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:106)
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:95)
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:67)
	at org.elasticsearch.gateway.GatewayMetaState.clusterChanged(GatewayMetaState.java:167)
	at org.elasticsearch.gateway.Gateway.clusterChanged(Gateway.java:185)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:610)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:09:34,272][ERROR][bootstrap                ] [Living Planet] Exception
org.jboss.netty.channel.ChannelException: Failed to create a selector.
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:362)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.<init>(AbstractNioWorker.java:52)
	at org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:45)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.newWorker(NioWorkerPool.java:44)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.newWorker(NioWorkerPool.java:28)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.init(AbstractNioWorkerPool.java:80)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:39)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:33)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:149)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:131)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.doStart(NettyHttpServerTransport.java:251)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.http.HttpServer.doStart(HttpServer.java:92)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.node.Node.start(Node.java:289)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:206)
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:272)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)
Caused by: java.io.IOException: Too many open files in system
	at sun.nio.ch.IOUtil.makePipe(Native Method)
	at sun.nio.ch.KQueueSelectorImpl.<init>(KQueueSelectorImpl.java:84)
	at sun.nio.ch.KQueueSelectorProvider.openSelector(KQueueSelectorProvider.java:42)
	at java.nio.channels.Selector.open(Selector.java:227)
	at org.jboss.netty.channel.socket.nio.SelectorUtil.open(SelectorUtil.java:63)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:360)
	... 18 more
[2016-07-22 10:09:34,277][INFO ][node                     ] [Living Planet] stopping ...
[2016-07-22 10:09:34,279][INFO ][discovery.zen            ] [Living Planet] failed to send join request to master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}], reason [IllegalStateException[Future got interrupted]; nested: InterruptedException; ]
[2016-07-22 10:09:34,345][WARN ][cluster.service          ] [Cloud] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,346][WARN ][cluster.service          ] [Eternal Brain] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,352][WARN ][cluster.service          ] [Mauler] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,352][WARN ][cluster.service          ] [Siryn] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,343][WARN ][cluster.service          ] [Giant-Man] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,358][WARN ][cluster.service          ] [Primevil] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,361][WARN ][cluster.service          ] [Geiger] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,365][WARN ][cluster.service          ] [Hugh Jones] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,366][WARN ][cluster.service          ] [Jimaine Szardos] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,372][WARN ][cluster.service          ] [Xandu] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,339][WARN ][cluster.service          ] [Joshua Guthrie] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,355][WARN ][cluster.service          ] [Myron MacLain] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,345][WARN ][cluster.service          ] [Aminedi] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,377][WARN ][cluster.service          ] [Outrage] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,368][WARN ][cluster.service          ] [Red Ghost] failed to connect to node [{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Living Planet][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:09:34,396][INFO ][cluster.service          ] [Siege] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-node_left({Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317})
[2016-07-22 10:09:34,403][INFO ][cluster.service          ] [Jimaine Szardos] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,403][INFO ][cluster.service          ] [Aminedi] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,406][INFO ][cluster.service          ] [Joshua Guthrie] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,406][INFO ][cluster.service          ] [Red Ghost] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,405][INFO ][cluster.service          ] [Cloud] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,407][INFO ][cluster.service          ] [Geiger] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,408][INFO ][cluster.service          ] [Outrage] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,401][DEBUG][action.admin.cluster.node.stats] [Siege] failed to execute on node [x98ZBccLSC6zXqLQItybNg]
SendRequestTransportException[[Living Planet][127.0.0.1:9317][cluster:monitor/nodes/stats[n]]]; nested: NodeNotConnectedException[[Living Planet][127.0.0.1:9317] Node not connected];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:340)
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.start(TransportNodesAction.java:164)
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$100(TransportNodesAction.java:106)
	at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:76)
	at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:46)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:137)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:85)
	at org.elasticsearch.cluster.InternalClusterInfoService.updateNodeStats(InternalClusterInfoService.java:289)
	at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:325)
	at org.elasticsearch.cluster.InternalClusterInfoService.maybeRefresh(InternalClusterInfoService.java:310)
	at org.elasticsearch.cluster.InternalClusterInfoService.access$600(InternalClusterInfoService.java:69)
	at org.elasticsearch.cluster.InternalClusterInfoService$2.run(InternalClusterInfoService.java:202)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: NodeNotConnectedException[[Living Planet][127.0.0.1:9317] Node not connected]
	at org.elasticsearch.transport.netty.NettyTransport.nodeChannel(NettyTransport.java:1132)
	at org.elasticsearch.transport.netty.NettyTransport.sendRequest(NettyTransport.java:819)
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:329)
	... 14 more
[2016-07-22 10:09:34,404][INFO ][cluster.service          ] [Eternal Brain] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,411][INFO ][cluster.service          ] [Myron MacLain] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,413][INFO ][cluster.service          ] [Hugh Jones] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,416][INFO ][cluster.service          ] [Xandu] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,416][INFO ][cluster.service          ] [Siryn] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,406][INFO ][cluster.service          ] [Giant-Man] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,423][INFO ][cluster.service          ] [Primevil] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,423][INFO ][cluster.service          ] [Mauler] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:34,424][INFO ][cluster.service          ] [Jerry Jaxon] removed {{Living Planet}{x98ZBccLSC6zXqLQItybNg}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:09:35,235][INFO ][node                     ] [Living Planet] stopped
[2016-07-22 10:09:35,236][INFO ][node                     ] [Living Planet] closing ...
[2016-07-22 10:09:35,243][INFO ][node                     ] [Living Planet] closed
[2016-07-22 10:10:33,986][INFO ][node                     ] [Mole Man] version[2.3.4], pid[1675], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 10:10:33,987][INFO ][node                     ] [Mole Man] initializing ...
[2016-07-22 10:10:35,052][INFO ][plugins                  ] [Mole Man] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 10:10:35,090][INFO ][env                      ] [Mole Man] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [254.4gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 10:10:35,091][INFO ][env                      ] [Mole Man] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 10:10:35,092][WARN ][env                      ] [Mole Man] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 10:10:37,911][INFO ][node                     ] [Mole Man] initialized
[2016-07-22 10:10:37,913][INFO ][node                     ] [Mole Man] starting ...
[2016-07-22 10:10:38,040][INFO ][transport                ] [Mole Man] publish_address {127.0.0.1:9317}, bound_addresses {[fe80::1]:9317}, {[::1]:9317}, {127.0.0.1:9317}
[2016-07-22 10:10:38,045][INFO ][discovery                ] [Mole Man] elasticsearch/bTIb-iI4SHGs0mANBq4HHw
[2016-07-22 10:10:41,139][INFO ][cluster.service          ] [Siege] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-join(join from node[{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}])
[2016-07-22 10:10:41,142][INFO ][cluster.service          ] [Jerry Jaxon] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,142][INFO ][cluster.service          ] [Siryn] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,142][INFO ][cluster.service          ] [Myron MacLain] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,145][INFO ][cluster.service          ] [Joshua Guthrie] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,146][INFO ][cluster.service          ] [Xandu] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,145][INFO ][cluster.service          ] [Red Ghost] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,148][INFO ][cluster.service          ] [Jimaine Szardos] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,149][INFO ][cluster.service          ] [Mole Man] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,151][INFO ][cluster.service          ] [Eternal Brain] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,151][INFO ][cluster.service          ] [Mauler] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,154][INFO ][cluster.service          ] [Cloud] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,144][INFO ][cluster.service          ] [Hugh Jones] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,156][INFO ][cluster.service          ] [Giant-Man] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,156][INFO ][cluster.service          ] [Geiger] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,158][INFO ][cluster.service          ] [Primevil] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,150][INFO ][cluster.service          ] [Aminedi] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,152][INFO ][cluster.service          ] [Outrage] added {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,225][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:10:41,226][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308}]
ConnectTransportException[[Cloud][127.0.0.1:9308] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:974)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,227][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:10:41,230][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:10:41,230][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313}]
ConnectTransportException[[Geiger][127.0.0.1:9313] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,233][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:10:41,232][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,234][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:10:41,234][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312}]
ConnectTransportException[[Hugh Jones][127.0.0.1:9312] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,236][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,236][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:10:41,237][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301}]
ConnectTransportException[[Aminedi][127.0.0.1:9301] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,239][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304}]
ConnectTransportException[[Myron MacLain][127.0.0.1:9304] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,239][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:10:41,237][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:10:41,240][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306}]
ConnectTransportException[[Red Ghost][127.0.0.1:9306] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,242][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309}]
ConnectTransportException[[Eternal Brain][127.0.0.1:9309] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,243][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303}]
ConnectTransportException[[Jerry Jaxon][127.0.0.1:9303] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,242][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:10:41,244][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305}]
ConnectTransportException[[Outrage][127.0.0.1:9305] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,246][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,247][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:10:41,247][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307}]
ConnectTransportException[[Siryn][127.0.0.1:9307] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,248][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302}]
ConnectTransportException[[Joshua Guthrie][127.0.0.1:9302] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,249][WARN ][cluster.service          ] [Mole Man] failed to connect to node [{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311}]
ConnectTransportException[[Mauler][127.0.0.1:9311] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:10:41,313][WARN ][cluster.service          ] [Mauler] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,316][WARN ][cluster.service          ] [Siryn] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,341][ERROR][bootstrap                ] [Mole Man] Exception
BindTransportException[Failed to resolve publish address]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.http.netty.NettyHttpServerTransport.createBoundHttpAddress(NettyHttpServerTransport.java:294)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.doStart(NettyHttpServerTransport.java:273)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.http.HttpServer.doStart(HttpServer.java:92)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.node.Node.start(Node.java:289)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:206)
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:272)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)
Caused by: java.net.SocketException: Too many open files in system
	at java.net.NetworkInterface.getAll(Native Method)
	at java.net.NetworkInterface.getNetworkInterfaces(NetworkInterface.java:343)
	at org.elasticsearch.common.network.NetworkUtils.getInterfaces(NetworkUtils.java:127)
	at org.elasticsearch.common.network.NetworkUtils.getLoopbackAddresses(NetworkUtils.java:155)
	at org.elasticsearch.common.network.NetworkService.resolveInternal(NetworkService.java:227)
	at org.elasticsearch.common.network.NetworkService.resolveInetAddresses(NetworkService.java:209)
	at org.elasticsearch.common.network.NetworkService.resolvePublishHostAddresses(NetworkService.java:167)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.createBoundHttpAddress(NettyHttpServerTransport.java:292)
	... 8 more
[2016-07-22 10:10:41,345][INFO ][node                     ] [Mole Man] stopping ...
[2016-07-22 10:10:41,347][INFO ][discovery.zen            ] [Mole Man] failed to send join request to master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}], reason [IllegalStateException[Future got interrupted]; nested: InterruptedException; ]
[2016-07-22 10:10:41,426][WARN ][cluster.service          ] [Cloud] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,449][WARN ][cluster.service          ] [Primevil] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,436][WARN ][cluster.service          ] [Giant-Man] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,439][WARN ][cluster.service          ] [Geiger] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,442][WARN ][cluster.service          ] [Eternal Brain] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,461][WARN ][cluster.service          ] [Xandu] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,446][WARN ][cluster.service          ] [Aminedi] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,465][WARN ][cluster.service          ] [Jimaine Szardos] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,464][WARN ][cluster.service          ] [Hugh Jones] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,435][WARN ][cluster.service          ] [Joshua Guthrie] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,429][WARN ][cluster.service          ] [Outrage] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,430][WARN ][cluster.service          ] [Myron MacLain] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,450][WARN ][cluster.service          ] [Jerry Jaxon] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,440][WARN ][cluster.service          ] [Red Ghost] failed to connect to node [{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mole Man][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:10:41,474][DEBUG][action.admin.cluster.node.stats] [Siege] failed to execute on node [bTIb-iI4SHGs0mANBq4HHw]
SendRequestTransportException[[Mole Man][127.0.0.1:9317][cluster:monitor/nodes/stats[n]]]; nested: NodeNotConnectedException[[Mole Man][127.0.0.1:9317] Node not connected];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:340)
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.start(TransportNodesAction.java:164)
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$100(TransportNodesAction.java:106)
	at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:76)
	at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:46)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:137)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:85)
	at org.elasticsearch.cluster.InternalClusterInfoService.updateNodeStats(InternalClusterInfoService.java:289)
	at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:325)
	at org.elasticsearch.cluster.InternalClusterInfoService.maybeRefresh(InternalClusterInfoService.java:310)
	at org.elasticsearch.cluster.InternalClusterInfoService.access$600(InternalClusterInfoService.java:69)
	at org.elasticsearch.cluster.InternalClusterInfoService$2.run(InternalClusterInfoService.java:202)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: NodeNotConnectedException[[Mole Man][127.0.0.1:9317] Node not connected]
	at org.elasticsearch.transport.netty.NettyTransport.nodeChannel(NettyTransport.java:1132)
	at org.elasticsearch.transport.netty.NettyTransport.sendRequest(NettyTransport.java:819)
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:329)
	... 14 more
[2016-07-22 10:10:41,476][INFO ][cluster.service          ] [Siege] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-node_left({Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317})
[2016-07-22 10:10:41,481][INFO ][cluster.service          ] [Outrage] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,483][INFO ][cluster.service          ] [Myron MacLain] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,483][INFO ][cluster.service          ] [Giant-Man] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,484][INFO ][cluster.service          ] [Joshua Guthrie] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,485][INFO ][cluster.service          ] [Jimaine Szardos] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,486][INFO ][cluster.service          ] [Jerry Jaxon] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,487][INFO ][cluster.service          ] [Cloud] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,488][INFO ][cluster.service          ] [Hugh Jones] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,489][INFO ][cluster.service          ] [Geiger] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,491][INFO ][cluster.service          ] [Xandu] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,487][INFO ][cluster.service          ] [Red Ghost] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,492][INFO ][cluster.service          ] [Eternal Brain] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,491][INFO ][cluster.service          ] [Aminedi] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,483][INFO ][cluster.service          ] [Siryn] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,495][INFO ][cluster.service          ] [Mauler] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:41,497][INFO ][cluster.service          ] [Primevil] removed {{Mole Man}{bTIb-iI4SHGs0mANBq4HHw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:10:42,243][INFO ][node                     ] [Mole Man] stopped
[2016-07-22 10:10:42,244][INFO ][node                     ] [Mole Man] closing ...
[2016-07-22 10:10:42,251][INFO ][node                     ] [Mole Man] closed
[2016-07-22 10:12:27,929][INFO ][node                     ] [Mister Buda] version[2.3.4], pid[1737], build[e455fd0/2016-06-30T11:24:31Z]
[2016-07-22 10:12:27,930][INFO ][node                     ] [Mister Buda] initializing ...
[2016-07-22 10:12:28,872][INFO ][plugins                  ] [Mister Buda] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2016-07-22 10:12:28,939][INFO ][env                      ] [Mister Buda] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [254.4gb], net total_space [464.6gb], spins? [unknown], types [hfs]
[2016-07-22 10:12:28,940][INFO ][env                      ] [Mister Buda] heap size [990.7mb], compressed ordinary object pointers [true]
[2016-07-22 10:12:28,946][WARN ][env                      ] [Mister Buda] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-07-22 10:12:31,478][INFO ][node                     ] [Mister Buda] initialized
[2016-07-22 10:12:31,478][INFO ][node                     ] [Mister Buda] starting ...
[2016-07-22 10:12:31,616][INFO ][transport                ] [Mister Buda] publish_address {127.0.0.1:9317}, bound_addresses {[fe80::1]:9317}, {[::1]:9317}, {127.0.0.1:9317}
[2016-07-22 10:12:31,622][INFO ][discovery                ] [Mister Buda] elasticsearch/uxx7IUh6TUSoTmv19FIJjw
[2016-07-22 10:12:34,717][INFO ][cluster.service          ] [Siege] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-join(join from node[{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}])
[2016-07-22 10:12:34,737][INFO ][cluster.service          ] [Siryn] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,738][INFO ][cluster.service          ] [Jerry Jaxon] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,740][INFO ][cluster.service          ] [Myron MacLain] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,743][INFO ][cluster.service          ] [Geiger] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,749][INFO ][cluster.service          ] [Joshua Guthrie] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,749][INFO ][cluster.service          ] [Primevil] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,749][INFO ][cluster.service          ] [Jimaine Szardos] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,751][INFO ][cluster.service          ] [Xandu] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,752][INFO ][cluster.service          ] [Aminedi] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,754][INFO ][cluster.service          ] [Eternal Brain] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,756][INFO ][cluster.service          ] [Mauler] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,756][INFO ][cluster.service          ] [Cloud] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,758][INFO ][cluster.service          ] [Giant-Man] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,755][INFO ][cluster.service          ] [Outrage] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,758][INFO ][cluster.service          ] [Red Ghost] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,763][INFO ][cluster.service          ] [Hugh Jones] added {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,769][INFO ][cluster.service          ] [Mister Buda] detected_master {Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}, added {{Aminedi}{SSnVPscAQoCov44svGwSyQ}{127.0.0.1}{127.0.0.1:9301},{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310},{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300},{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312},{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307},{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316},{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306},{Myron MacLain}{o5IOcsZaSpKa6-a_W_zgQQ}{127.0.0.1}{127.0.0.1:9304},{Eternal Brain}{Nn30dk_1TAetMMwupV72Hg}{127.0.0.1}{127.0.0.1:9309},{Joshua Guthrie}{8v_mme0bQSOuVjlGsMp_Cg}{127.0.0.1}{127.0.0.1:9302},{Geiger}{PMeMoLg4TEG0FWdOPXOXvw}{127.0.0.1}{127.0.0.1:9313},{Cloud}{jOV2nqHGTZCTsZaL05xnRA}{127.0.0.1}{127.0.0.1:9308},{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314},{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315},{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305},{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311},{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:34,812][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:12:34,812][WARN ][cluster.service          ] [Mister Buda] failed to connect to node [{Primevil}{6eglDmQTSOWzzDFIatEeKA}{127.0.0.1}{127.0.0.1:9310}]
ConnectTransportException[[Primevil][127.0.0.1:9310] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:971)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:12:34,837][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:12:34,814][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:12:34,837][WARN ][cluster.service          ] [Mister Buda] failed to connect to node [{Hugh Jones}{2BHKFjIxT1-BoXUEx9d92w}{127.0.0.1}{127.0.0.1:9312}]
ConnectTransportException[[Hugh Jones][127.0.0.1:9312] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:12:34,872][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:12:34,871][WARN ][cluster.service          ] [Mister Buda] failed to connect to node [{Siryn}{nJhvAF8mQyaz1AJLR8L8FQ}{127.0.0.1}{127.0.0.1:9307}]
ConnectTransportException[[Siryn][127.0.0.1:9307] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:12:34,875][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:12:34,874][WARN ][cluster.service          ] [Mister Buda] failed to connect to node [{Xandu}{EGvpHQ-qTkWIN0ACb0dceQ}{127.0.0.1}{127.0.0.1:9316}]
ConnectTransportException[[Xandu][127.0.0.1:9316] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:12:34,878][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:12:34,941][WARN ][cluster.service          ] [Siryn] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:34,952][WARN ][cluster.service          ] [Jimaine Szardos] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:987)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:34,877][WARN ][cluster.service          ] [Mister Buda] failed to connect to node [{Red Ghost}{ajK1yIvBS1GjMHXskFRa7g}{127.0.0.1}{127.0.0.1:9306}]
ConnectTransportException[[Red Ghost][127.0.0.1:9306] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:12:35,031][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:12:34,963][WARN ][cluster.service          ] [Myron MacLain] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:34,956][WARN ][cluster.service          ] [Jerry Jaxon] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:34,942][WARN ][cluster.service          ] [Red Ghost] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: SocketException[Connection reset by peer];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset by peer
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,031][WARN ][cluster.service          ] [Mister Buda] failed to connect to node [{Giant-Man}{MXO4JMzzTnqLZNSMtzTdFA}{127.0.0.1}{127.0.0.1:9314}]
ConnectTransportException[[Giant-Man][127.0.0.1:9314] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:971)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:12:35,056][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:12:35,055][WARN ][cluster.service          ] [Mister Buda] failed to connect to node [{Jimaine Szardos}{fPTuo0I5T_yORPS1MOBRaw}{127.0.0.1}{127.0.0.1:9315}]
ConnectTransportException[[Jimaine Szardos][127.0.0.1:9315] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:12:35,060][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:12:35,059][WARN ][cluster.service          ] [Mister Buda] failed to connect to node [{Outrage}{xbEPXtpzSoyBevWMLImNWA}{127.0.0.1}{127.0.0.1:9305}]
ConnectTransportException[[Outrage][127.0.0.1:9305] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:12:35,063][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:12:35,062][WARN ][cluster.service          ] [Mister Buda] failed to connect to node [{Mauler}{pc2ZepAzRFu3BVm0pgYzdg}{127.0.0.1}{127.0.0.1:9311}]
ConnectTransportException[[Mauler][127.0.0.1:9311] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:12:35,066][WARN ][cluster.service          ] [Mister Buda] failed to connect to node [{Jerry Jaxon}{1W5bz2ywT3CetwfAdfjCZw}{127.0.0.1}{127.0.0.1:9303}]
ConnectTransportException[[Jerry Jaxon][127.0.0.1:9303] general node connection failure]; nested: ChannelException[Failed to open a socket.]; nested: SocketException[Too many open files in system];
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:937)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.jboss.netty.channel.ChannelException: Failed to open a socket.
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:43)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.<init>(NioClientSocketChannel.java:82)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:212)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.newChannel(NioClientSocketChannelFactory.java:82)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:212)
	at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:182)
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:968)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	... 9 more
Caused by: java.net.SocketException: Too many open files in system
	at sun.nio.ch.Net.socket0(Native Method)
	at sun.nio.ch.Net.socket(Net.java:411)
	at sun.nio.ch.Net.socket(Net.java:404)
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannel.newSocket(NioClientSocketChannel.java:41)
	... 16 more
[2016-07-22 10:12:35,067][WARN ][netty.channel.socket.nio.AbstractNioSelector] Failed to accept a connection.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-22 10:12:35,104][ERROR][bootstrap                ] [Mister Buda] Exception
org.jboss.netty.channel.ChannelException: Failed to create a selector.
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:362)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.<init>(AbstractNioWorker.java:52)
	at org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:45)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.newWorker(NioWorkerPool.java:44)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.newWorker(NioWorkerPool.java:28)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.init(AbstractNioWorkerPool.java:80)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:39)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:33)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:149)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:131)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.doStart(NettyHttpServerTransport.java:251)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.http.HttpServer.doStart(HttpServer.java:92)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)
	at org.elasticsearch.node.Node.start(Node.java:289)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:206)
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:272)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)
Caused by: java.io.IOException: Too many open files in system
	at sun.nio.ch.KQueueArrayWrapper.init(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.<init>(KQueueArrayWrapper.java:98)
	at sun.nio.ch.KQueueSelectorImpl.<init>(KQueueSelectorImpl.java:88)
	at sun.nio.ch.KQueueSelectorProvider.openSelector(KQueueSelectorProvider.java:42)
	at java.nio.channels.Selector.open(Selector.java:227)
	at org.jboss.netty.channel.socket.nio.SelectorUtil.open(SelectorUtil.java:63)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:360)
	... 18 more
[2016-07-22 10:12:35,111][INFO ][node                     ] [Mister Buda] stopping ...
[2016-07-22 10:12:35,113][INFO ][discovery.zen            ] [Mister Buda] failed to send join request to master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}], reason [IllegalStateException[Future got interrupted]; nested: InterruptedException; ]
[2016-07-22 10:12:35,133][WARN ][cluster.service          ] [Xandu] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,131][WARN ][cluster.service          ] [Geiger] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,136][WARN ][cluster.service          ] [Cloud] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,127][WARN ][cluster.service          ] [Primevil] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,148][WARN ][cluster.service          ] [Eternal Brain] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:1005)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,148][WARN ][cluster.service          ] [Outrage] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,151][WARN ][cluster.service          ] [Mauler] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,159][WARN ][cluster.service          ] [Aminedi] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,234][WARN ][cluster.service          ] [Hugh Jones] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,235][WARN ][cluster.service          ] [Giant-Man] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,234][WARN ][cluster.service          ] [Joshua Guthrie] failed to connect to node [{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317}]
ConnectTransportException[[Mister Buda][127.0.0.1:9317] connect_timeout[30s]]; nested: ConnectException[Connection refused: /127.0.0.1:9317];
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:996)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:920)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:893)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:260)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:590)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9317
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2016-07-22 10:12:35,243][INFO ][cluster.service          ] [Siege] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-node_left({Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317})
[2016-07-22 10:12:35,247][INFO ][cluster.service          ] [Outrage] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,249][INFO ][cluster.service          ] [Primevil] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,251][INFO ][cluster.service          ] [Mauler] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,253][INFO ][cluster.service          ] [Eternal Brain] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,254][INFO ][cluster.service          ] [Cloud] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,256][INFO ][cluster.service          ] [Red Ghost] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,257][INFO ][cluster.service          ] [Aminedi] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,257][INFO ][cluster.service          ] [Jerry Jaxon] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,259][INFO ][cluster.service          ] [Joshua Guthrie] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,260][INFO ][cluster.service          ] [Jimaine Szardos] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,262][INFO ][cluster.service          ] [Giant-Man] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,264][INFO ][cluster.service          ] [Myron MacLain] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,266][INFO ][cluster.service          ] [Siryn] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,267][INFO ][cluster.service          ] [Geiger] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,267][INFO ][cluster.service          ] [Hugh Jones] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,269][INFO ][cluster.service          ] [Xandu] removed {{Mister Buda}{uxx7IUh6TUSoTmv19FIJjw}{127.0.0.1}{127.0.0.1:9317},}, reason: zen-disco-receive(from master [{Siege}{OrsWhLlQS0CuQTIKBNrKJA}{127.0.0.1}{127.0.0.1:9300}])
[2016-07-22 10:12:35,246][DEBUG][action.admin.cluster.node.stats] [Siege] failed to execute on node [uxx7IUh6TUSoTmv19FIJjw]
SendRequestTransportException[[Mister Buda][127.0.0.1:9317][cluster:monitor/nodes/stats[n]]]; nested: NodeNotConnectedException[[Mister Buda][127.0.0.1:9317] Node not connected];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:340)
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.start(TransportNodesAction.java:164)
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$100(TransportNodesAction.java:106)
	at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:76)
	at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:46)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:137)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:85)
	at org.elasticsearch.cluster.InternalClusterInfoService.updateNodeStats(InternalClusterInfoService.java:289)
	at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:325)
	at org.elasticsearch.cluster.InternalClusterInfoService.maybeRefresh(InternalClusterInfoService.java:310)
	at org.elasticsearch.cluster.InternalClusterInfoService.access$600(InternalClusterInfoService.java:69)
	at org.elasticsearch.cluster.InternalClusterInfoService$2.run(InternalClusterInfoService.java:202)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: NodeNotConnectedException[[Mister Buda][127.0.0.1:9317] Node not connected]
	at org.elasticsearch.transport.netty.NettyTransport.nodeChannel(NettyTransport.java:1132)
	at org.elasticsearch.transport.netty.NettyTransport.sendRequest(NettyTransport.java:819)
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:329)
	... 14 more
[2016-07-22 10:12:35,880][INFO ][node                     ] [Mister Buda] stopped
[2016-07-22 10:12:35,880][INFO ][node                     ] [Mister Buda] closing ...
[2016-07-22 10:12:35,894][INFO ][node                     ] [Mister Buda] closed
